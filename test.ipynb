{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b411edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hexdump\n",
    "\n",
    "path = \"sch_data/my_sch_data\"\n",
    "\n",
    "with open(f\"{path}/DESDOC.DAT\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "dump_str = hexdump.dump(data)\n",
    "\n",
    "# Save it to a .txt file for inspection\n",
    "with open(f\"{path}/desdoc_dump.txt\", \"w\") as out_file:\n",
    "    out_file.write(dump_str)\n",
    "\n",
    "print(f\"Hexdump saved to {path}/desdoc_dump.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb942186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "# ======== CONFIGURATION ========\n",
    "file_path = \"sch_data/cccc_sch_data/DESDOC.DAT\"  # Update path if needed\n",
    "\n",
    "# Load data\n",
    "data = load_file(file_path)\n",
    "\n",
    "# Markers for AAAA, BBBB, CCCC\n",
    "marker_aaaa = b'\\x41\\x00\\x41\\x00\\x41\\x00\\x41\\x00'\n",
    "marker_bbbb = b'\\x42\\x00\\x42\\x00\\x42\\x00\\x42\\x00'\n",
    "marker_cccc = b'\\x43\\x00\\x43\\x00\\x43\\x00\\x43\\x00'\n",
    "\n",
    "# Locate offsets\n",
    "offset_aaaa = data.find(marker_aaaa)\n",
    "offset_bbbb = data.find(marker_bbbb)\n",
    "offset_cccc = data.find(marker_cccc)\n",
    "\n",
    "# Report findings\n",
    "print(f\"AAAA offset: {hex(offset_aaaa) if offset_aaaa != -1 else 'Not Found'}\")\n",
    "print(f\"BBBB offset: {hex(offset_bbbb) if offset_bbbb != -1 else 'Not Found'}\")\n",
    "print(f\"CCCC offset: {hex(offset_cccc) if offset_cccc != -1 else 'Not Found'}\")\n",
    "\n",
    "# Check and compute block sizes\n",
    "if offset_aaaa != -1 and offset_bbbb != -1:\n",
    "    block_size1 = offset_bbbb - offset_aaaa\n",
    "    print(f\"Block size AAAA to BBBB: {block_size1} bytes\")\n",
    "else:\n",
    "    print(\"Could not compute block size between AAAA and BBBB.\")\n",
    "\n",
    "if offset_bbbb != -1 and offset_cccc != -1:\n",
    "    block_size2 = offset_cccc - offset_bbbb\n",
    "    print(f\"Block size BBBB to CCCC: {block_size2} bytes\")\n",
    "else:\n",
    "    print(\"Could not compute block size between BBBB and CCCC.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def read_null_terminated_utf16_name(data, start_offset, max_bytes=64):\n",
    "    \"\"\"\n",
    "    Reads a variable-length UTF-16LE string, stopping at null terminator or max_bytes.\n",
    "    \"\"\"\n",
    "    name_bytes = bytearray()\n",
    "    for i in range(0, max_bytes, 2):\n",
    "        chunk = data[start_offset + i:start_offset + i + 2]\n",
    "        if len(chunk) < 2 or chunk == b'\\x00\\x00':\n",
    "            break\n",
    "        name_bytes.extend(chunk)\n",
    "    try:\n",
    "        return name_bytes.decode('utf-16-le')\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "# ======== CONFIGURATION ========\n",
    "file_path = \"sch_data/my_sch_data/DESDOC.DAT\"\n",
    "\n",
    "# Load data\n",
    "data = load_file(file_path)\n",
    "\n",
    "# Schematic count stored at byte 5\n",
    "schematic_count = data[5]\n",
    "print(f\"Detected {schematic_count} schematic(s).\\n\")\n",
    "\n",
    "# Find the first schematic marker offset\n",
    "first_marker_offset = data.find(\n",
    "    b'\\x41\\x00\\x41\\x00\\x41\\x00\\x41\\x00')  # AAAA marker\n",
    "\n",
    "if first_marker_offset == -1:\n",
    "    print(\"First schematic marker not found.\")\n",
    "else:\n",
    "    print(f\"First schematic marker found at {hex(first_marker_offset)}\")\n",
    "\n",
    "    # Set block size based on your earlier measurements\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    print(f\"Scanning {schematic_count} live schematic blocks...\\n\")\n",
    "\n",
    "    # Iterate only live schematics\n",
    "    for i in range(schematic_count):\n",
    "        block_start = first_marker_offset + (i * BLOCK_SIZE)\n",
    "        schematic_name = read_null_terminated_utf16_name(\n",
    "            data, block_start, max_bytes=64)\n",
    "        print(f\"Block {i + 1} at offset {hex(block_start)}: {schematic_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def save_file(path, data):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "\n",
    "def read_null_terminated_utf16_name(data, start_offset, max_bytes=64):\n",
    "    name_bytes = bytearray()\n",
    "    for i in range(0, max_bytes, 2):\n",
    "        chunk = data[start_offset + i:start_offset + i + 2]\n",
    "        if len(chunk) < 2 or chunk == b'\\x00\\x00':\n",
    "            break\n",
    "        name_bytes.extend(chunk)\n",
    "    try:\n",
    "        return name_bytes.decode('utf-16-le')\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def export_schematic(save_path, output_dir):\n",
    "    data = load_file(save_path)\n",
    "    schematic_count = data[5]\n",
    "    print(f\"Detected {schematic_count} schematic(s).\")\n",
    "\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure export directory exists\n",
    "\n",
    "    for i in range(schematic_count):\n",
    "        block_start = first_marker_offset + (i * BLOCK_SIZE)\n",
    "        block_data = data[block_start:block_start + BLOCK_SIZE]\n",
    "        name = read_null_terminated_utf16_name(\n",
    "            block_data, 0, max_bytes=64).strip()\n",
    "        safe_name = name if name else f\"Slot{i+1}\"\n",
    "        file_name = f\"{safe_name}_Slot{i+1}.acfa\"\n",
    "        save_file(os.path.join(output_dir, file_name), block_data)\n",
    "        print(f\"Exported {file_name}\")\n",
    "\n",
    "\n",
    "def import_schematic(save_path, acfa_path, slot_number):\n",
    "    data = bytearray(load_file(save_path))\n",
    "    schematic_data = load_file(acfa_path)\n",
    "\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    target_offset = first_marker_offset + ((slot_number - 1) * BLOCK_SIZE)\n",
    "\n",
    "    if len(schematic_data) != BLOCK_SIZE:\n",
    "        print(\"❌ Invalid schematic file size.\")\n",
    "        return\n",
    "\n",
    "    data[target_offset:target_offset + BLOCK_SIZE] = schematic_data\n",
    "    save_file(save_path, data)\n",
    "    print(f\"✅ Inserted {os.path.basename(acfa_path)} into Slot {slot_number}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Export:\n",
    "#export_schematic(\"sch_data/aaaa_sch_data/DESDOC.DAT\", \"exports\")\n",
    "\n",
    "# Example Import:\n",
    "import_schematic(\"sch_data/bbbb_sch_data/DESDOC.DAT\",\n",
    "                 \"exports/AAAA_Slot1.acfa\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=64):\n",
    "    \"\"\"\n",
    "    Reads UTF-16LE and stops at the first non-alphanumeric sequence to remove residuals.\n",
    "    \"\"\"\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def is_block_empty(block):\n",
    "    return all(b == 0 for b in block)\n",
    "\n",
    "\n",
    "def list_schematic_names_smart(file_path, max_slots=200):\n",
    "    data = load_file(file_path)\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    print(\"Scanning for schematics...\\n\")\n",
    "    slot_index = 0\n",
    "\n",
    "    while True:\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "        if block_start + BLOCK_SIZE > len(data):\n",
    "            break\n",
    "\n",
    "        block = data[block_start:block_start + BLOCK_SIZE]\n",
    "        if is_block_empty(block):\n",
    "            break\n",
    "\n",
    "        schematic_name = linear_utf16_clean_name_reader(\n",
    "            data, block_start, max_bytes=64)\n",
    "        print(f\"Slot {slot_index + 1} at {hex(block_start)}: {schematic_name}\")\n",
    "\n",
    "        slot_index += 1\n",
    "        if slot_index >= max_slots:\n",
    "            print(\"Reached max slot scan limit.\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "list_schematic_names_smart(\"sch_data/my_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed279eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import binascii\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def dump_slot_hex(file_path, slot_indices, context_bytes=64):\n",
    "    data = load_file(file_path)\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    for slot_index in slot_indices:\n",
    "        block_start = first_marker_offset + ((slot_index - 1) * BLOCK_SIZE)\n",
    "        block = data[block_start:block_start + context_bytes]\n",
    "\n",
    "        print(\n",
    "            f\"--- Slot {slot_index} at {hex(block_start)} (first {context_bytes} bytes) ---\")\n",
    "        print(binascii.hexlify(block).decode('ascii'))\n",
    "        print()\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "# Dump slots 10, 11, and 13 from your save\n",
    "dump_slot_hex(\"sch_data/my_sch_data/DESDOC.DAT\",\n",
    "              [10, 11, 13], context_bytes=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import binascii\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def dump_block(data, offset, block_size=24280, context_bytes=32):\n",
    "    block = data[offset:offset + block_size]\n",
    "    print(f\"\\n==== Dumping Block at {hex(offset)} ====\")\n",
    "    print(binascii.hexlify(block[:context_bytes]).decode('ascii') + \" ...\")\n",
    "    return block\n",
    "\n",
    "\n",
    "def compare_blocks(file_path, offset_a, offset_b, block_size=24280):\n",
    "    data = load_file(file_path)\n",
    "    block_a = data[offset_a:offset_a + block_size]\n",
    "    block_b = data[offset_b:offset_b + block_size]\n",
    "\n",
    "    if block_a == block_b:\n",
    "        print(\"Blocks are IDENTICAL.\")\n",
    "    else:\n",
    "        print(\"Blocks DIFFER. Dumping differences:\")\n",
    "        for i in range(min(len(block_a), len(block_b))):\n",
    "            if block_a[i] != block_b[i]:\n",
    "                print(\n",
    "                    f\"Offset {hex(i)}: {hex(block_a[i])} != {hex(block_b[i])}\")\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "# Known offsets from earlier runs\n",
    "OFFSET_KOMARIK = 0x4d241\n",
    "OFFSET_KOMAR_1 = 0x5eec9\n",
    "OFFSET_KOMAR_2 = 0x64da1\n",
    "\n",
    "file_path = \"sch_data/my_sch_data/DESDOC.DAT\"\n",
    "\n",
    "# Compare Komarik vs Komar 1\n",
    "compare_blocks(file_path, OFFSET_KOMARIK, OFFSET_KOMAR_1)\n",
    "\n",
    "# Optionally compare Komarik vs Komar 2\n",
    "compare_blocks(file_path, OFFSET_KOMARIK, OFFSET_KOMAR_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf812f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=64):\n",
    "    \"\"\"\n",
    "    Reads UTF-16LE and stops at the first non-alphanumeric sequence to remove residuals.\n",
    "    \"\"\"\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def is_block_empty(block):\n",
    "    return all(b == 0 for b in block)\n",
    "\n",
    "\n",
    "def is_marked_deleted(data, name_end_offset):\n",
    "    \"\"\"\n",
    "    Checks if the two bytes immediately after the schematic name are 00 6E.\n",
    "    \"\"\"\n",
    "    marker = data[name_end_offset:name_end_offset + 2]\n",
    "    return marker == b'\\x6E\\x00'\n",
    "\n",
    "\n",
    "def list_schematic_names_smart(file_path, max_slots=200):\n",
    "    data = load_file(file_path)\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    print(\"Scanning for schematics...\\n\")\n",
    "    slot_index = 0\n",
    "\n",
    "    while True:\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "        if block_start + BLOCK_SIZE > len(data):\n",
    "            break\n",
    "\n",
    "        block = data[block_start:block_start + BLOCK_SIZE]\n",
    "        if is_block_empty(block):\n",
    "            break\n",
    "\n",
    "        # Read schematic name and calculate its end offset\n",
    "        raw_field = data[block_start:block_start + 64]\n",
    "        try:\n",
    "            null_index = raw_field.index(b'\\x00\\x00')\n",
    "            name_bytes = raw_field[:null_index]\n",
    "        except ValueError:\n",
    "            name_bytes = raw_field\n",
    "\n",
    "        name_end_offset = block_start + len(name_bytes)\n",
    "\n",
    "        schematic_name = linear_utf16_clean_name_reader(\n",
    "            data, block_start, max_bytes=64)\n",
    "\n",
    "        deleted_flag = is_marked_deleted(data, name_end_offset)\n",
    "        marker_bytes = data[name_end_offset:name_end_offset + 2].hex()\n",
    "        status = \"Deleted\" if deleted_flag else \"Active\"\n",
    "\n",
    "        print(\n",
    "            f\"Slot {slot_index + 1} at {hex(block_start)}: {schematic_name} ({status}, marker: {marker_bytes})\")\n",
    "\n",
    "\n",
    "        slot_index += 1\n",
    "        if slot_index >= max_slots:\n",
    "            print(\"Reached max slot scan limit.\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "list_schematic_names_smart(\"sch_data/my_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcfe3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=64):\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def is_block_empty(block):\n",
    "    return all(b == 0 for b in block)\n",
    "\n",
    "\n",
    "def detect_deletion_by_padding_and_marker(data, block_start, name_length_bytes):\n",
    "    marker = data[block_start +\n",
    "                  name_length_bytes:block_start + name_length_bytes + 4]\n",
    "    if marker == b'\\x00\\x00\\x6E\\x00':\n",
    "        trailing_data = data[block_start + name_length_bytes +\n",
    "                             4:block_start + name_length_bytes + 64]\n",
    "        if all(b == 0 for b in trailing_data):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def list_schematic_names_smart(file_path, max_slots=200):\n",
    "    data = load_file(file_path)\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    print(\"Scanning for schematics with deletion heuristic...\\n\")\n",
    "    slot_index = 0\n",
    "\n",
    "    while True:\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "        if block_start + BLOCK_SIZE > len(data):\n",
    "            break\n",
    "\n",
    "        block = data[block_start:block_start + BLOCK_SIZE]\n",
    "        if is_block_empty(block):\n",
    "            break\n",
    "\n",
    "        raw_field = data[block_start:block_start + 64]\n",
    "        try:\n",
    "            null_index = raw_field.index(b'\\x00\\x00')\n",
    "            name_bytes = raw_field[:null_index]\n",
    "        except ValueError:\n",
    "            name_bytes = raw_field\n",
    "\n",
    "        name_length_bytes = len(name_bytes)\n",
    "        schematic_name = linear_utf16_clean_name_reader(\n",
    "            data, block_start, max_bytes=64)\n",
    "\n",
    "        is_deleted = detect_deletion_by_padding_and_marker(\n",
    "            data, block_start, name_length_bytes)\n",
    "\n",
    "        status = \"Deleted\" if is_deleted else \"Active\"\n",
    "        print(\n",
    "            f\"Slot {slot_index + 1} at {hex(block_start)}: {schematic_name} ({status})\")\n",
    "\n",
    "        slot_index += 1\n",
    "        if slot_index >= max_slots:\n",
    "            print(\"Reached max slot scan limit.\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "list_schematic_names_smart(\"sch_data/del_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2daa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_block_previews(file_path, count=5):\n",
    "    data = load_file(file_path)\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    for slot_index in range(count):\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "        block = data[block_start:block_start + BLOCK_SIZE]\n",
    "        print(\n",
    "            f\"Slot {slot_index + 1} at {hex(block_start)}: {linear_utf16_clean_name_reader(data, block_start)}\")\n",
    "        print(f\"  Block preview: {' '.join(f'{b:02X}' for b in block[:64])}\\n\")\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "dump_block_previews(\"sch_data/del_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=64):\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def dump_extended_block_previews(file_path, slot_count=5, preview_size=256):\n",
    "    data = load_file(file_path)\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    for slot_index in range(slot_count):\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "        block = data[block_start:block_start + BLOCK_SIZE]\n",
    "        schematic_name = linear_utf16_clean_name_reader(data, block_start)\n",
    "        print(f\"Slot {slot_index + 1} at {hex(block_start)}: {schematic_name}\")\n",
    "        print(\"  Extended preview:\")\n",
    "        preview_bytes = block[:preview_size]\n",
    "        print('  ' + ' '.join(f'{b:02X}' for b in preview_bytes))\n",
    "        print()\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "dump_extended_block_previews(\"sch_data/del_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfffcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def extract_block(data, block_start, block_size=24280):\n",
    "    return data[block_start:block_start + block_size]\n",
    "\n",
    "\n",
    "def compare_blocks(label1, block1, label2, block2):\n",
    "    print(f\"\\nComparing {label1} and {label2}:\\n\")\n",
    "    length = min(len(block1), len(block2))\n",
    "    differences_found = False\n",
    "\n",
    "    for i in range(0, length, 16):\n",
    "        b1_slice = block1[i:i+16]\n",
    "        b2_slice = block2[i:i+16]\n",
    "\n",
    "        hex_b1 = ' '.join(f'{b:02X}' for b in b1_slice)\n",
    "        hex_b2 = ' '.join(f'{b:02X}' for b in b2_slice)\n",
    "\n",
    "        diff_marker = ''.join(\n",
    "            '  ' if b1_slice[j] == b2_slice[j] else '^^' for j in range(len(b1_slice)))\n",
    "\n",
    "        if any(b1_slice[j] != b2_slice[j] for j in range(len(b1_slice))):\n",
    "            differences_found = True\n",
    "\n",
    "        print(f\"{i:04X}: {hex_b1:<48} | {hex_b2:<48} | {diff_marker}\")\n",
    "\n",
    "    if not differences_found:\n",
    "        print(\"\\nNo differences found.\\n\")\n",
    "    else:\n",
    "        print(\"\\nDifferences marked with ^^.\\n\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = \"sch_data/del_sch_data/DESDOC.DAT\"\n",
    "data = load_file(file_path)\n",
    "\n",
    "# Provide the start offsets of Slot 2 and Slot 4\n",
    "slot2_start = 0x6021\n",
    "slot4_start = 0x11dd1\n",
    "\n",
    "block2 = extract_block(data, slot2_start)\n",
    "block4 = extract_block(data, slot4_start)\n",
    "\n",
    "compare_blocks(\"Slot 2 (Deleted)\", block2, \"Slot 4 (Deleted)\", block4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f815635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def compare_blocks(file_path, offset1, offset2, block_size=24280, preview_size=256):\n",
    "    data = load_file(file_path)\n",
    "\n",
    "    block1 = data[offset1:offset1 + block_size][:preview_size]\n",
    "    block2 = data[offset2:offset2 + block_size][:preview_size]\n",
    "\n",
    "    print(f\"\\nComparing blocks at {hex(offset1)} and {hex(offset2)}:\\n\")\n",
    "    for i in range(0, preview_size, 16):\n",
    "        b1 = block1[i:i+16]\n",
    "        b2 = block2[i:i+16]\n",
    "        hex_b1 = ' '.join(f'{byte:02X}' for byte in b1)\n",
    "        hex_b2 = ' '.join(f'{byte:02X}' for byte in b2)\n",
    "        marker = '  ' + \\\n",
    "            ''.join('|' if j < len(b1) and b1[j] !=\n",
    "                    b2[j] else ' ' for j in range(len(b1)))\n",
    "        print(f'{i:04X}: {hex_b1:<47} | {hex_b2:<47}{marker}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    file_path = \"sch_data/del_sch_data/DESDOC.DAT\"\n",
    "\n",
    "    # Known slots (adjust these if your offsets change)\n",
    "    active_1_offset = 0x149   # Slot 1 (Active)\n",
    "    active_2_offset = 0xbef9  # Slot 3 (Active)\n",
    "\n",
    "    deleted_1_offset = 0x6021  # Slot 2 (Deleted)\n",
    "    deleted_2_offset = 0x11dd1  # Slot 4 (Deleted)\n",
    "\n",
    "    # Active vs Active\n",
    "    compare_blocks(file_path, active_1_offset, active_2_offset)\n",
    "\n",
    "    # Deleted vs Deleted\n",
    "    compare_blocks(file_path, deleted_1_offset, deleted_2_offset)\n",
    "\n",
    "    # Active vs Deleted (first pair)\n",
    "    compare_blocks(file_path, active_1_offset, deleted_1_offset)\n",
    "\n",
    "    # Active vs Deleted (second pair)\n",
    "    compare_blocks(file_path, active_2_offset, deleted_2_offset)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcddeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_schematic(file_path, src_offset, dest_offset, block_size=24280):\n",
    "    data = bytearray(load_file(file_path))\n",
    "\n",
    "    # Copy block from src_offset\n",
    "    block_data = data[src_offset:src_offset + block_size]\n",
    "\n",
    "    # Paste over dest_offset\n",
    "    data[dest_offset:dest_offset + block_size] = block_data\n",
    "\n",
    "    # Save to a new file\n",
    "    restored_path = file_path + \".restored\"\n",
    "    with open(restored_path, \"wb\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "    print(\n",
    "        f\"Restored block from {hex(src_offset)} to {hex(dest_offset)} in {restored_path}\")\n",
    "    \n",
    "\n",
    "restore_schematic(\"sch_data/del_sch_data/DESDOC.DAT\", 0x149, 0x6021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ef5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_metadata(file_path, source_offset, target_offset, metadata_offset_in_block, length=8):\n",
    "    data = bytearray(load_file(file_path))\n",
    "\n",
    "    # Compute absolute positions\n",
    "    src_pos = source_offset + metadata_offset_in_block\n",
    "    dst_pos = target_offset + metadata_offset_in_block\n",
    "\n",
    "    # Copy metadata\n",
    "    metadata = data[src_pos:src_pos + length]\n",
    "    data[dst_pos:dst_pos + length] = metadata\n",
    "\n",
    "    # Save to a new file\n",
    "    patched_path = file_path + \".patched\"\n",
    "    with open(patched_path, \"wb\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "    print(\n",
    "        f\"Patched {length} bytes from {hex(src_pos)} to {hex(dst_pos)} in {patched_path}\")\n",
    "\n",
    "\n",
    "patch_metadata(\"sch_data/del_sch_data/DESDOC.DAT\", 0x149, 0x6021, 0x00C0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be868a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=64):\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def is_block_empty(block):\n",
    "    return all(b == 0 for b in block)\n",
    "\n",
    "\n",
    "def list_active_schematic_names_and_designers(file_path):\n",
    "    data = load_file(file_path)\n",
    "    schematic_count = data[5]\n",
    "    print(f\"Detected {schematic_count} active schematic(s).\\n\")\n",
    "\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "    NAME_SIZE = 96  # 48 wchar_t = 96 bytes\n",
    "\n",
    "    for slot_index in range(schematic_count):\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "\n",
    "        name_offset = block_start\n",
    "        designer_offset = block_start + NAME_SIZE\n",
    "\n",
    "        schematic_name = linear_utf16_clean_name_reader(\n",
    "            data, name_offset, max_bytes=NAME_SIZE)\n",
    "        designer_name = linear_utf16_clean_name_reader(\n",
    "            data, designer_offset, max_bytes=NAME_SIZE)\n",
    "\n",
    "        print(\n",
    "            f\"Slot {slot_index + 1} at {hex(block_start)}: {schematic_name} by {designer_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46937743",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_active_schematic_names_and_designers(\"sch_data/my_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c85171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import struct\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=96):\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def read_timestamp(data, offset):\n",
    "    # Timestamp is an 8-byte unsigned integer\n",
    "    timestamp_bytes = data[offset:offset + 8]\n",
    "    # Big-endian unsigned long long\n",
    "    return struct.unpack(\">Q\", timestamp_bytes)[0]\n",
    "\n",
    "\n",
    "def list_active_schematics(file_path):\n",
    "    data = load_file(file_path)\n",
    "    schematic_count = data[5]\n",
    "    print(f\"Detected {schematic_count} active schematic(s).\\n\")\n",
    "\n",
    "    first_marker_offset = 0x148  # Corrected offset\n",
    "    BLOCK_SIZE = 24280\n",
    "\n",
    "    for slot_index in range(schematic_count):\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "\n",
    "        # Read schematic name and designer name (each 96 bytes = 48 wchar_t = 96 bytes in UTF-16)\n",
    "        name_offset = block_start\n",
    "        designer_offset = block_start + 96\n",
    "        timestamp_offset = block_start + 192  # 96 + 96\n",
    "\n",
    "        schematic_name = linear_utf16_clean_name_reader(\n",
    "            data, name_offset + 1, max_bytes=96)\n",
    "        designer_name = linear_utf16_clean_name_reader(\n",
    "            data, designer_offset + 1, max_bytes=96)\n",
    "        timestamp = read_timestamp(data, timestamp_offset)\n",
    "\n",
    "        # Category/protect byte follows timestamp (at offset +8)\n",
    "        protect_category_byte_offset = timestamp_offset + 8\n",
    "        protect_category_byte = data[protect_category_byte_offset]\n",
    "        protect = (protect_category_byte & 0b10000000) >> 7\n",
    "        category = (protect_category_byte & 0b01111111) + \\\n",
    "            1  # Adjusted to match User 01-based display\n",
    "\n",
    "        print(f\"Slot {slot_index + 1} at {hex(block_start)}:\")\n",
    "        print(f\"  Name: {schematic_name}\")\n",
    "        print(f\"  Designer: {designer_name}\")\n",
    "        print(f\"  Protect: {protect}\")\n",
    "        print(f\"  User Slot: {category}\")\n",
    "        print(f\"  Raw Byte: 0x{protect_category_byte:02x}\")\n",
    "        print(f\"  Timestamp: {timestamp}\")\n",
    "        print()\n",
    "\n",
    "# Example Usage:\n",
    "list_active_schematics(\"sch_data/my_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59216c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=64):\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 _-]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def extract_schematic_by_slot(file_path, slot_number, output_folder=\"exports\"):\n",
    "    data = load_file(file_path)\n",
    "    schematic_count = data[5]\n",
    "\n",
    "    if not (1 <= slot_number <= schematic_count):\n",
    "        print(f\"Invalid slot number. Valid range is 1 to {schematic_count}.\")\n",
    "        return\n",
    "\n",
    "    first_marker_offset = 0x149\n",
    "    BLOCK_SIZE = 24280\n",
    "    NAME_SIZE = 96  # 48 wchar_t = 96 bytes\n",
    "\n",
    "    block_start = first_marker_offset + (slot_number - 1) * BLOCK_SIZE\n",
    "\n",
    "    schematic_name = linear_utf16_clean_name_reader(\n",
    "        data, block_start, NAME_SIZE)\n",
    "    designer_name = linear_utf16_clean_name_reader(\n",
    "        data, block_start + NAME_SIZE, NAME_SIZE)\n",
    "\n",
    "    # Sanitize file name\n",
    "    safe_schematic_name = re.sub(\n",
    "        r'[^A-Za-z0-9 _-]', '', schematic_name) or \"Unknown\"\n",
    "    safe_designer_name = re.sub(\n",
    "        r'[^A-Za-z0-9 _-]', '', designer_name) or \"Unknown\"\n",
    "    filename = f\"{safe_schematic_name}-{safe_designer_name}.ac4a\"\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "    # Write the block to file\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(data[block_start:block_start + BLOCK_SIZE])\n",
    "\n",
    "    print(f\"Schematic in slot {slot_number} extracted to: {output_path}\")\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_schematic_by_slot(\"sch_data/my_sch_data/DESDOC.DAT\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def save_file(path, data):\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "\n",
    "def insert_schematic(ac4a_path, desdoc_path):\n",
    "    ac4a_data = load_file(ac4a_path)\n",
    "    desdoc_data = bytearray(load_file(desdoc_path))\n",
    "\n",
    "    BLOCK_SIZE = 24280\n",
    "    schematic_count_offset = 5  # The byte that holds the active schematic count\n",
    "    first_marker_offset = 0x149\n",
    "\n",
    "    active_schematic_count = desdoc_data[schematic_count_offset]\n",
    "    print(f\"Current active schematic count: {active_schematic_count}\")\n",
    "\n",
    "    insertion_offset = first_marker_offset + \\\n",
    "        (active_schematic_count * BLOCK_SIZE)\n",
    "\n",
    "    # Ensure the insertion is within bounds\n",
    "    if insertion_offset + BLOCK_SIZE > len(desdoc_data):\n",
    "        print(\"Error: Not enough space to insert schematic.\")\n",
    "        return\n",
    "\n",
    "    # Insert schematic data\n",
    "    desdoc_data[insertion_offset:insertion_offset +\n",
    "                BLOCK_SIZE] = ac4a_data[:BLOCK_SIZE]\n",
    "\n",
    "    # Increment schematic count\n",
    "    desdoc_data[schematic_count_offset] += 1\n",
    "    print(\n",
    "        f\"New schematic inserted at slot {active_schematic_count + 1} (offset {hex(insertion_offset)}). New count: {desdoc_data[schematic_count_offset]}\")\n",
    "\n",
    "    # Write the modified file\n",
    "    save_file(desdoc_path, desdoc_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d55844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "insert_schematic(\"exports/Sbeu Komarik-Vlabus.ac4a\", \"sch_data/aaaa_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ccf111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 8 active schematic(s).\n",
      "\n",
      "Slot 1:\n",
      "  Name: AAAA\n",
      "  Designer: Vlabus\n",
      "  Protect: 0\n",
      "  User Slot: 1\n",
      "  Raw Byte: 0x00\n",
      "  Timestamp: 63882918406832434\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "Slot 2:\n",
      "  Name: Bomber\n",
      "  Designer: Inveigh\n",
      "  Protect: 0\n",
      "  User Slot: 1\n",
      "  Raw Byte: 0x00\n",
      "  Timestamp: 63861092783094213\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "Slot 3:\n",
      "  Name: Sniper\n",
      "  Designer: Inveigh\n",
      "  Protect: 0\n",
      "  User Slot: 1\n",
      "  Raw Byte: 0x00\n",
      "  Timestamp: 63856408134194256\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "Slot 4:\n",
      "  Name: BEZELTANK\n",
      "  Designer: BEZEL\n",
      "  Protect: 0\n",
      "  User Slot: 1\n",
      "  Raw Byte: 0x00\n",
      "  Timestamp: 63856408697989959\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "Slot 5:\n",
      "  Name: Sbeu Shmel\n",
      "  Designer: Vlabus\n",
      "  Protect: 0\n",
      "  User Slot: 2\n",
      "  Raw Byte: 0x01\n",
      "  Timestamp: 63882961789730868\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "Slot 6:\n",
      "  Name: Sbeu Komarik\n",
      "  Designer: Vlabus\n",
      "  Protect: 0\n",
      "  User Slot: 2\n",
      "  Raw Byte: 0x01\n",
      "  Timestamp: 63882927513523055\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "Slot 7:\n",
      "  Name: Sbeu Tarakan\n",
      "  Designer: Vlabus\n",
      "  Protect: 0\n",
      "  User Slot: 2\n",
      "  Raw Byte: 0x01\n",
      "  Timestamp: 63883041354520147\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "Slot 8:\n",
      "  Name: Sbeu SBIH\n",
      "  Designer: Vlabius\n",
      "  Protect: 0\n",
      "  User Slot: 3\n",
      "  Raw Byte: 0x02\n",
      "  Timestamp: 63882158259055003\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import struct\n",
    "\n",
    "BLOCK_SIZE = 24280\n",
    "NAME_SIZE = 96  # 48 wchar_t = 96 bytes in UTF-16\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=96):\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def read_timestamp(data, offset):\n",
    "    timestamp_bytes = data[offset:offset + 8]\n",
    "    return struct.unpack(\">Q\", timestamp_bytes)[0]\n",
    "\n",
    "\n",
    "def extract_active_schematic_blocks(file_path):\n",
    "    data = load_file(file_path)\n",
    "    schematic_count = data[5]\n",
    "    blocks = []\n",
    "    first_marker_offset = 0x148\n",
    "\n",
    "    for slot_index in range(schematic_count):\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "        block = data[block_start:block_start + BLOCK_SIZE]\n",
    "        blocks.append(block)\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def display_schematic_info(block):\n",
    "    schematic_name = linear_utf16_clean_name_reader(block, 1, NAME_SIZE)\n",
    "    designer_name = linear_utf16_clean_name_reader(\n",
    "        block, 1 + NAME_SIZE, NAME_SIZE)\n",
    "    timestamp = read_timestamp(block, 192)\n",
    "\n",
    "    protect_category_byte = block[200]\n",
    "    protect = (protect_category_byte & 0b10000000) >> 7\n",
    "    category = (protect_category_byte & 0b01111111) + 1\n",
    "\n",
    "    parts = extract_parts(block)\n",
    "    tuning = extract_tuning(block)\n",
    "\n",
    "    schematic_info = {\n",
    "        \"name\": schematic_name,\n",
    "        \"designer\": designer_name,\n",
    "        \"protect\": protect,\n",
    "        \"category\": category,\n",
    "        \"raw_byte\": protect_category_byte,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"parts\": parts,\n",
    "        \"tuning\": tuning\n",
    "    }\n",
    "\n",
    "    # Optional print for debugging\n",
    "    print(f\"  Name: {schematic_info['name']}\")\n",
    "    print(f\"  Designer: {schematic_info['designer']}\")\n",
    "    print(f\"  Protect: {schematic_info['protect']}\")\n",
    "    print(f\"  User Slot: {schematic_info['category']}\")\n",
    "    print(f\"  Raw Byte: 0x{schematic_info['raw_byte']:02x}\")\n",
    "    print(f\"  Timestamp: {schematic_info['timestamp']}\")\n",
    "    print(\"  Parts:\", schematic_info['parts'])\n",
    "    print(\"  Tuning:\", schematic_info['tuning'])\n",
    "    print()\n",
    "\n",
    "    return schematic_info\n",
    "\n",
    "\n",
    "def extract_parts(block):\n",
    "    # Placeholder: parts data starts after 0xC9 (201) + 15 + 40 (Parts structure start)\n",
    "    parts_offset = 201 + 15\n",
    "    # Assuming Parts block is 76 bytes long based on field sizes (38 ushorts * 2)\n",
    "    parts_block = block[parts_offset:parts_offset + 76]\n",
    "    return [\"<Part ID List Placeholder>\"]  # Replace later\n",
    "\n",
    "\n",
    "def extract_tuning(block):\n",
    "    # Placeholder: tuning data starts after parts (201 + 15 + 76)\n",
    "    tuning_offset = 201 + 15 + 76\n",
    "    tuning_block = block[tuning_offset:tuning_offset + 32]  # 32 tuning bytes\n",
    "    return [\"<Tuning Values Placeholder>\"]  # Replace later\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"sch_data/my_sch_data/DESDOC.DAT\"\n",
    "blocks = extract_active_schematic_blocks(file_path)\n",
    "print(f\"Detected {len(blocks)} active schematic(s).\\n\")\n",
    "\n",
    "for idx, block in enumerate(blocks, 1):\n",
    "    print(f\"Slot {idx}:\")\n",
    "    display_schematic_info(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0402263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def save_schematic_block_as_ac4a(hex_block: bytes):\n",
    "    \"\"\"\n",
    "    Saves a single schematic block to a .ac4a file.\n",
    "    Example output_path: 'output/my_schematic.ac4a'\n",
    "    \"\"\"\n",
    "    sch_data = display_schematic_info(hex_block)\n",
    "    schematic_name = sch_data['name']\n",
    "    designer_name = sch_data['designer']\n",
    "    output_path = f\"output/{schematic_name}_{designer_name}.ac4a\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(hex_block)\n",
    "\n",
    "\n",
    "def load_schematic_block_from_ac4a(file_path: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Loads a schematic block from a .ac4a file.\n",
    "    Returns the raw bytes representing the schematic block.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2965e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name: Sbeu SBIH\n",
      "  Designer: Vlabius\n",
      "  Protect: 0\n",
      "  User Slot: 3\n",
      "  Raw Byte: 0x02\n",
      "  Timestamp: 63882158259055003\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n",
      "  Name: Sbeu SBIH\n",
      "  Designer: Vlabius\n",
      "  Protect: 0\n",
      "  User Slot: 3\n",
      "  Raw Byte: 0x02\n",
      "  Timestamp: 63882158259055003\n",
      "  Parts: ['<Part ID List Placeholder>']\n",
      "  Tuning: ['<Tuning Values Placeholder>']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Sbeu SBIH',\n",
       " 'designer': 'Vlabius',\n",
       " 'protect': 0,\n",
       " 'category': 3,\n",
       " 'raw_byte': 2,\n",
       " 'timestamp': 63882158259055003,\n",
       " 'parts': ['<Part ID List Placeholder>'],\n",
       " 'tuning': ['<Tuning Values Placeholder>']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save block 1 to .ac4a file\n",
    "save_schematic_block_as_ac4a(blocks[7])\n",
    "\n",
    "# Load it back\n",
    "loaded_block = load_schematic_block_from_ac4a(\"output/Sbeu SBIH_Vlabius.ac4a\")\n",
    "\n",
    "# Verify loaded block content by displaying its information\n",
    "display_schematic_info(loaded_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446a582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0010: GAN01-SS-AL\n",
      "0041: GAN02-NSS-A\n",
      "3010: 047AN03\n",
      "3021: 063AN03\n",
      "4010: A01-TELLUS\n",
      "1010: AM-HOGIRE\n",
      "1031: AM-LANCEL\n",
      "5031: EKHAZAR-ARMS\n",
      "2010: 03-AALIYAH/A\n",
      "7011: WHITE-GLINT/ARMS\n",
      "4041: A11-LATONA\n",
      "1020: AM-JUDITH\n",
      "1041: AM-LAHIRE\n",
      "5010: SOLUH-ARMS\n",
      "6011: XAM-SOBRERO\n",
      "2020: LINSTANT/A\n",
      "0020: GAN01-SS-A\n",
      "4020: HILBERT-G7A\n",
      "4061: SOLDNER-G8A\n",
      "0051: ARGYROS/A\n",
      "0030: GAN01-SS-AW\n",
      "0071: RAIDEN-AW\n",
      "5120: SAUTEES-ARMS\n",
      "5041: EKLAKH-ARMS\n",
      "4051: A12-OPS\n",
      "0061: ARGYROS/XA\n",
      "2130: MADNESS/XA\n",
      "4030: A06-AURORA\n",
      "9000: AM-LANCEL\n",
      "9010: 047AN03\n",
      "9121: 45_Aspina\n"
     ]
    }
   ],
   "source": [
    "def parse_part_mapping(file_path):\n",
    "    part_mapping = {}\n",
    "    current_category = None\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "\n",
    "            # Detect category header like 'Head (0):'\n",
    "            if line.endswith('):'):\n",
    "                category_name, category_id = line[:-2].rsplit('(', 1)\n",
    "                current_category = category_name.strip()\n",
    "                part_mapping[current_category] = {}\n",
    "                continue\n",
    "\n",
    "            if current_category is None:\n",
    "                continue  # Skip any lines before first category\n",
    "\n",
    "            # Split the line into part_id and part_name\n",
    "            if ' ' in line:\n",
    "                part_id, part_name = line.split(' ', 1)\n",
    "                part_mapping[current_category][part_id.strip()\n",
    "                                               ] = part_name.strip()\n",
    "\n",
    "    return part_mapping\n",
    "\n",
    "\n",
    "# Example usage\n",
    "part_mapping = parse_part_mapping(\"ACFA_PS3_US_PARTID_TO_PARTNAME.txt\")\n",
    "\n",
    "# Example: print all head parts\n",
    "for part_id, part_name in part_mapping.get('Arms', {}).items():\n",
    "    print(f\"{part_id}: {part_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'Head': {'0031': 'GAN02-NSS-H', '3010': '047AN02', '3021': '063AN02', '4010': 'H01-TELLUS', '1010': 'HD-HOGIRE', '1041': 'HD-LANCEL', '5021': 'EKHAZAR-HEAD', '2010': '03-AALIYAH/H', '7011': 'WHITE-GLINT/HEAD', '4031': 'H11-LATONA', '1020': 'HD-JUDITH', '1030': 'HD-HOLOFERNES', '1051': 'HD-LAHIRE', '5010': 'SOLUH-HEAD', '6011': 'XHD-SOBRERO', '2020': 'LINSTANT/H', '0010': 'GAN01-SS-H', '0020': 'KIRITUMI-H', '4020': 'HILBERT-G7H', '4041': 'SOLDNER-G8H', '0041': 'ARGYROS/H', '9000': 'HD-LANCEL', '9010': '047AN02', '9300': '063AN02'}, 'Core': {'0021': 'GAN02-NSS-C', '3010': '047AN01', '3021': '063AN01', '4010': 'C01-TELLUS', '1010': 'CR-HOGIRE', '1021': 'CR-LANCEL', '5021': 'EKHAZAR-CORE', '2010': '03-AALIYAH/C', '7011': 'WHITE-GLINT/CORE', '4021': 'C11-LATONA', '1031': 'CR-LAHIRE', '5010': 'SOLUH-CORE', '6011': 'XCR-SOBRERO', '0010': 'GAN01-SS-C', '4031': 'SOLDNER-G8C', '0031': 'ARGYROS/C', '9000': 'CR-LANCEL', '9010': '047AN01', '9100': 'VOB'}, 'Arms': {'0010': 'GAN01-SS-AL', '0041': 'GAN02-NSS-A', '3010': '047AN03', '3021': '063AN03', '4010': 'A01-TELLUS', '1010': 'AM-HOGIRE', '1031': 'AM-LANCEL', '5031': 'EKHAZAR-ARMS', '2010': '03-AALIYAH/A', '7011': 'WHITE-GLINT/ARMS', '4041': 'A11-LATONA', '1020': 'AM-JUDITH', '1041': 'AM-LAHIRE', '5010': 'SOLUH-ARMS', '6011': 'XAM-SOBRERO', '2020': 'LINSTANT/A', '0020': 'GAN01-SS-A', '4020': 'HILBERT-G7A', '4061': 'SOLDNER-G8A', '0051': 'ARGYROS/A', '0030': 'GAN01-SS-AW', '0071': 'RAIDEN-AW', '5120': 'SAUTEES-ARMS', '5041': 'EKLAKH-ARMS', '4051': 'A12-OPS', '0061': 'ARGYROS/XA', '2130': 'MADNESS/XA', '4030': 'A06-AURORA', '9000': 'AM-LANCEL', '9010': '047AN03', '9121': '45_Aspina'}, 'Legs': {'0010': 'GAN01-SS-LL', '0051': 'GAN02-NSS-L', '3010': '047AN04', '3031': '063AN04', '4010': 'L01-TELLUS', '1010': 'LG-HOGIRE', '1031': 'LG-LANCEL', '2010': '03-AALIYAH/L', '7011': 'WHITE-GLINT/LEGS', '4041': 'L11-LATONA', '1020': 'LG-JUDITH', '1041': 'LG-LAHIRE', '5010': 'SOLUH-LEGS', '6011': 'XLG-SOBRERO', '2030': 'LINSTANT/L', '0020': 'GAN01-SS-L', '4030': 'HILBERT-G7L', '4061': 'SOLDNER-G8L', '0061': 'ARGYROS/L', '4071': 'SOLDNER-G9L', '5120': 'SAUBEES-LEGS', '5031': 'EKHAZAR-LEGS', '2120': '04-ALICIA/L', '0230': 'GAEN01-SL-L', '3220': '049AN04', '3041': '061AN04', '5041': 'DUSKAROR-LEGS', '0340': 'KIRITUMI-L', '0071': 'RAIDEN-L', '4320': 'L02-ALBIREO', '4051': 'L09-RIGEL', '9000': 'LG-LANCEL', '9010': '049AN04'}, 'FCS': {'0010': 'YELLOWSTONE01', '0020': 'YELLOWSTONE03', '0030': '047AN05', '3021': '061AN05', '3031': '063AN05', '0031': 'OMNIA', '1010': 'FS-HOGIRE', '1020': 'FS-JUDITH', '1031': 'FS-LAHIRE', '5011': 'EKHAZAR-FCS', '2010': 'INBLUE', '2020': 'LAURA', '2030': 'BLUEXS', '9000': '047AN05', '9010': '047AN05'}, 'Generator': {'0010': 'GAN01-SS-GL', '0031': 'GAN02-NSS-G', '0051': 'I-RIGEL/G', '1010': 'GN-HOGIRE', '1020': 'GN-HECTOR', '5011': 'EKHAZAR-GEN', '2010': '03-AALIYAH/G', '1030': 'GN-JUDITH', '1041': 'GN-LAHIRE', '1051': 'GN-SOBRERO', '2030': 'LINSTANT/G', '0020': 'GAN01-SS-G', '0041': 'ARGYROS/G', '2020': 'S08-MAXWELL', '9000': 'GN-HOGIRE', '9010': 'GN-HOGIRE'}, 'Main Booster': {'0010': 'GAN01-SS-ML.CG', '0031': 'GAN02-NSS-M.CG', '1020': 'CB-HOGIRE', '5011': 'EKHAZAR-CORB', '5021': 'DUSKAROR-CORB', '2020': '03-AALIYAH/M', '2010': 'S04-VIRTUE', '4021': 'MB11-LATONA', '1010': 'CB-RACHEL', '1030': 'CB-JUDITH', '1041': 'CB-LAHIRE', '0020': 'GAN01-SS-M.CG', '4010': 'MB107-POLARIS', '0041': 'ARGYROS/M', '9000': 'CB-RACHEL', '9010': 'CB-RACHEL'}, 'Back Booster': {'0021': 'GAN02-NSS-B.CG', '1010': 'LB-HOGIRE', '5011': 'EKHAZAR-LEGB', '2010': '03-AALIYAH/B', '4021': 'BB11-LATONA', '1021': 'LB-LAHIRE', '0010': 'GAN01-SS-B.CG', '4010': 'BB103-SCHEAT', '0031': 'ARGYROS/B', '9000': 'LB-HOGIRE', '9010': '03-AALIYAH/B'}, 'Side Booster': {'0021': 'GAN02-NSS-S.CG', '1030': 'AB-HOGIRE', '5011': 'EKHAZAR-ARMB', '2020': '03-AALIYAH/S', '4021': 'SB11-LATONA', '1010': 'AB-JUDITH', '1020': 'AB-HOLOFERNES', '1041': 'AB-LAHIRE', '2010': 'S02-ORTEGA', '0010': 'GAN01-SS-S.CG', '4010': 'SB128-SCHEDAR', '0031': 'ARGYROS/S', '9000': 'AB-HOGIRE', '9010': 'AB-HOLOFERNES', '9020': 'AB-HOLOFERNES'}, 'Overed Booster': {'0021': 'GAN02-NSS-O.CG', '1020': 'KB-PALLAS', '2010': '03-AALIYAH/O', '1010': 'KB-JUDITH', '2030': 'LINSTANT/O', '0010': 'GAN01-SS-O.CG', '2020': 'S01-V3', '0031': 'GAP-AO.CG', '0051': 'I-RIGEL/AO', '1031': 'KRB-PALLAS', '1041': 'KRB-JUDITH', '1051': 'KRB-LAHIRE', '1061': 'KRB-SOBRERO', '0041': 'ARGYROS/AO', '9000': 'KB-JUDITH', '9010': '03-AALIYAH/O', '9020': '03-AALIYAH/O'}, 'Arm Unit': {'0091': 'GAN02-NSS-WR', '3010': '047ANNR', '3020': '051ANNR', '1010': 'RF-R100', '1020': 'MR-R100R', '5071': 'LABIATA', '2091': '063ANAR', '1030': 'MR-R102', '1091': 'AR-O700', '5010': 'ACACIA', '2010': '04-MARVE', '3030': '047ANSR', '3040': '050ANSR', '2101': '061ABSR', '5020': 'VANDA', '5081': 'CANTUTA', '6011': 'XMG-A030', '2020': '01-HITMAN', '2030': '03-MOTORCOBRA', '0010': 'GAN01-SS-WG', '0101': 'GAN01-SS-WGP', '1101': 'SG-O700', '5030': 'MBURUCUYA', '5040': 'SAMPAGUITA', '0040': 'GAN01-SS-WH.E', '0050': 'GAEN01-SL-WH', '5091': 'LARE', '0020': 'GAN01-SS-WB', '0030': 'GAN01-SS-WBP', '4121': 'BZ-BROCKEN', '0111': 'GAN02-NSS-WBS', '0070': 'SAKUNAMI', '0080': 'WADOU', '0171': 'NUKABIRA', '4131': 'GRA-TRAVERS', '4010': 'RG01-PITONE', '4081': 'RG03-KAPTEYN', '2111': '067ANLR', '4020': 'LR01-ANTARES', '4030': 'LR02-ALTAIR', '4091': 'LR04-AVIOR', '1071': 'ER-R500', '1040': 'ER-O200', '6021': 'ER-O705', '4040': 'HLR01-CANOPUS', '4050': 'HLR71-VEGA', '4101': 'HLR09-BECRUX', '4060': 'PG02-DENEB', '4070': 'PG03-SPICA', '1111': 'EG-O703', '0161': 'FLUORITE', '2060': 'SAMSARA', '2070': 'SOLO', '0131': 'ARSENIC', '0141': 'ARSINE', '2080': 'AXIS', '5050': 'MUDAN', '5101': 'KIKU', '0121': 'GAN01-SS-WD', '4111': 'LB-ELTANIN', '1081': 'EB-R500', '1060': 'EB-O305', '1050': 'EB-O600', '1121': 'EB-O700', '2040': '02-DRAGONSLAYER', '2050': '07-MOONLIGHT', '1131': 'KB-O004', '0060': 'NIOBRARA03', '0151': 'ALLEGHENY01', '5060': 'CPH-48', '9000': 'RF-R100', '9001': 'EB-R500', '9010': 'RF-R100', '9011': 'RF-R100'}, 'Back Unit': {'0030': 'PLATTE01', '0040': 'MUSSELSHELL', '0201': 'WHEELING01', '0020': 'VERMILLION01', '0050': 'POPLAR01', '2041': '063ANPM', '0090': 'OSAGE03', '0211': 'WHEELING03', '0100': 'CHEYENNE01', '0110': 'CHEYENNE02', '0221': 'SALINE05', '2051': '061ANCM', '0060': 'DEARBORN02', '0070': 'DEARBORN03', '0080': 'BIGSIOUX', '0161': 'BISMUTH', '0171': 'ZINC', '1010': 'MP-O200', '1020': 'MP-O200I', '1030': 'MP-O203', '1101': 'MP-O700', '1040': 'MP-O601JC', '1111': 'MP-O901', '4010': 'BM03-MEDUSA', '4020': 'BM05-LAMIA', '5010': 'CP-48', '5020': 'CP-49', '5051': 'CP-51', '5030': 'BVS-50', '3010': '049ANSC', '3020': '050ANSC', '2061': '061ANSC', '1091': 'CG-R500', '6011': 'XCG-B050', '0151': 'GAN01-SS-GC', '5041': 'KAMAL', '0130': 'OGOTO', '0140': 'YAMAGA', '4091': 'GRB-TRAVERS', '5061': 'SAPLA', '0231': 'OIGAMI', '4061': 'RC01-PHACT', '1050': 'EC-O300', '1060': 'EC-O307AB', '4050': 'HLC02-SIRIUS', '4081': 'HLC09-ACRUX', '4071': 'PC01-GEMMA', '2010': 'SULTAN', '2020': 'TRESOR', '0181': 'ARSENIKON', '2030': 'INSOLENCE', '0191': 'LETHALDOSE', '0120': 'MARIAS02', '3030': '047ANR', '3040': '050ANR', '2071': '061ANR', '4030': 'RD01-SIRENA', '4040': 'RD03-PANDORA', '1080': 'RDF-O200', '1121': 'RDF-O700', '1070': 'JADORE', '1131': 'ACB-O710', '9000': 'PLATTE01', '9010': 'EC-O300', '9100': 'Ac45test'}, 'Shoulder Unit': {'0030': 'BELTCREEK03', '0040': 'NEMAHA01', '0050': 'MUSSELSHELL', '0081': 'MUSKINGUM02', '2031': '061ANRM', '5020': 'LALIGURAS', '4020': 'SM01-SCYLLA', '5041': 'FSS-53', '2020': '09-FLICKER', '0010': 'GALLATIN02', '0071': 'GUYANDOTTE04', '3030': '051ANAM', '5031': 'YASMIN', '3020': '048ANEM', '3010': '051ANEM', '1010': 'AR-O401', '2041': '063ANEM', '2010': 'ADDICT', '1020': 'EUPHORIA', '0061': 'P-MARROW', '1031': 'ASB-O710', '9001': 'BoosterTest', '9000': 'SM01-SCYLLA', '9010': 'SM01-SCYLLA'}, 'Stabilizer Head Top': {'0010': 'GAN01-SS-HTS0', '0004': 'RAIDEN-HTS1', '0041': 'RAIDEN-HTS2', '4010': 'HTS01-TELLUS-A', '4020': 'HTS01-TELLUS-B', '0001': 'HD-LAHIRE-OPT01', '0011': 'HD-LAHIRE-OPT02', '0003': 'HD-LANCEL-OPT01', '0031': 'HD-LANCEL-OPT02', '0002': 'HD-LANCEL-OPT03', '0021': 'HD-LANCEL-OPT04', '5010': 'SOLUH-HEAD-1', '5020': 'SOLUH-HEAD-2', '5030': 'SAUBEES-HEAD-1', '5040': 'SAUBEES-HEAD-2', '2010': '03-AALIYAH/HTS1', '2020': '03-AALIYAH/HTS2', '0005': 'WHITE-GLINT/HORN'}, 'Stabilizer Head Side': {'0010': 'GAN01-SS-HSS0', '0002': 'HSS01-LATONA-A', '0021': 'HSS01-LATONA-B', '0001': 'HD-LAHIRE-OPT03', '0011': 'HD-LAHIRE-OPT04', '1010': 'HD-HOGIRE-OPT01', '1020': 'HD-HOGIRE-OPT02', '5010': 'SOLUH-HEAD-1', '5020': 'SOLUH-HEAD-2', '0003': 'EKHAZAR-HEAD-1', '0031': 'EKHAZAR-HEAD-2', '0004': 'DUSKAROR-HEAD-1', '0041': 'DUSKAROR-HEAD-2', '2010': '03-AALIYAH/HSS1', '2020': '03-AALIYAH/HSS2', '2030': 'MADNESS/HSS1', '2040': 'MADNESS/HSS2', '9000': 'test'}, 'Stabilizer Core Upper': {'0010': 'GAN01-SS-CUS0', '0030': 'GAN01-SS-CUS1', '0040': 'GAN01-SS-CUS2', '0002': 'CUS01-LATONA-A', '0021': 'CUS01-LATONA-B', '0003': 'SOLDNER-G8-CUSA', '0031': 'SOLDNER-G8-CUSB', '0001': 'CR-LANCEL-OPT01', '0011': 'CR-LANCEL-OPT02', '5010': 'SOLUH-CORE-1', '5020': 'SOLUH-CORE-2', '2010': '03-AALIYAH/CUS1', '2020': '03-AALIYAH/CUS2', '2030': 'MADNESS/CUS1', '2040': 'MADNESS/CUS2', '9000': 'test'}, 'Stabilizer Core Lower': {'0010': 'GAN01-SS-CLS0', '0003': 'GAN02-NSS-CLS1', '0031': 'GAN02-NSS-CLS2', '3010': '047AN01001', '3020': '047AN01002', '4010': 'CLS01-TELLUS-A', '4020': 'CLS01-TELLUS-B', '0001': 'CLS01-AURORA-A', '0011': 'CLS01-AURORA-B', '0002': 'CR-LAHIRE-OPT01', '0021': 'CR-LAHIRE-OPT02', '5010': 'SOLUH-CORE-1', '5020': 'SOLUH-CORE-2', '2010': '03-AALIYAH/CLS1', '2020': '03-AALIYAH/CLS2', '9000': 'test'}, 'Stabilizer Arms': {'0010': 'GAN01-SS-AS0', '0030': 'GAN01-SS-AS1', '0040': 'GAN01-SS-AS2', '0002': 'GAN02-NSS-AS1', '0021': 'GAN02-NSS-AS2', '0001': '063AN03001', '0011': '063AN03002', '1010': 'AM-HOGIRE-OPE01', '1020': 'AM-HOGIRE-OPE02', '0003': 'AM-LANCEL-OPT01', '0031': 'AM-LANCEL-OPT02', '5010': 'SOLUH-ARMS-1', '5020': 'SOLUH-ARMS-2', '2010': 'LINSTANT/AS1', '2020': 'LINSTANT/AS2', '9000': 'test'}, 'Stabilizer Legs Back': {'0010': 'GAN01-SS-LBS0', '0030': 'GAN01-SS-LBS1', '0040': 'GAN01-SS-LBS2', '0003': '063AN04001', '0031': '063AN04002', '4010': 'HILBERT-G7-LBSA', '4020': 'HILBERT-G7-LBSB', '0001': 'LG-LAHIRE-OPT01', '0011': 'LG-LAHIRE-OPT02', '1010': 'LG-HOGIRE-OPH01', '1020': 'LG-HOGIRE-OPH02', '0002': 'LG-LANCEL-OPT01', '0021': 'LG-LANCEL-OPT02', '2010': '03-AALIYAH/LBS1', '2020': '03-AALIYAH/LBS2', '9000': 'test'}, 'Stabilizer Legs Upper': {'0010': 'GAN01-SS-LUS0', '0030': 'GAN01-SS-LUS1', '0040': 'GAN01-SS-LUS2', '0003': 'GAN02-NSS-LUS1', '0031': 'GAN02-NSS-LUS2', '3010': '047AN04001', '3020': '047AN04002', '0002': 'SOLDNER-G8-LUSA', '0021': 'SOLDNER-G8-LUSB', '1010': 'LG-HOGIRE-OPF01', '1020': 'LG-HOGIRE-OPF02', '0001': 'SOLUH-LEGS-1', '0011': 'SOLUH-LEGS-2', '2010': '04-ALICIA/LUS1', '2020': '04-ALICIA/LUS2', '9000': 'test'}, 'Stabilizer Legs Middle': {'0010': 'GAN01-SS-LMS0', '0030': 'GAN01-SS-LMS1', '0040': 'GAN01-SS-LMS2', '3010': '047AN04101', '3020': '047AN04102', '0002': '063AN04003', '0021': '063AN04004', '1010': 'LG-HOGIRE-OPK01', '1020': 'LG-HOGIRE-OPK02', '0001': 'SOLUH-LEGS-3', '0011': 'SOLUH-LEGS-4', '0003': 'EKHAZAR-LEGS-1', '0031': 'EKHAZAR-LEGS-2', '2010': 'LINSTANT/LMS1', '2020': 'LINSTANT/LMS2', '9000': 'test'}, 'Stabilizer Legs Lower': {'0010': 'GAN01-SS-LLS0', '0030': 'GAN01-SS-LLS1', '0040': 'GAN01-SS-LLS2', '4010': 'LLS01-TELLUS-A', '4020': 'LLS01-TELLUS-B', '0001': 'ARGYROS/LLS1', '0011': 'ARGYROS/LLS2', '0003': 'SOLDNER-G8-LLSA', '0031': 'SOLDNER-G8-LLSB', '0002': 'LG-LAHIRE-OPT03', '0021': 'LG-LAHIRE-OPT04', '5010': 'SOLUH-LEGS-5', '5020': 'SOLUH-LEGS-6', '2010': 'MADNESS/LLS1', '2020': 'MADNESS/LLS2', '9000': 'test'}}\n"
     ]
    }
   ],
   "source": [
    "heads = part_mapping.get('Main Booster', {})\n",
    "print(heads)\n",
    "print(heads.get('3010'))\n",
    "print(part_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
