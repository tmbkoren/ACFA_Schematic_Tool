{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c42de69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Head', 'Core', 'Arms', 'Legs', 'FCS', 'Generator', 'Main Booster', 'Back Booster', 'Side Booster', 'Overed Booster', 'Arm Unit', 'Back Unit', 'Shoulder Unit', 'Stabilizer Head Top', 'Stabilizer Head Side', 'Stabilizer Core Upper', 'Stabilizer Core Lower', 'Stabilizer Arms', 'Stabilizer Legs Back', 'Stabilizer Legs Upper', 'Stabilizer Legs Middle', 'Stabilizer Legs Lower'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import struct\n",
    "import math\n",
    "import io\n",
    "import tempfile\n",
    "import random\n",
    "from typing import Tuple\n",
    "from wand.image import Image as WandImage\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "ACFA_THUMBNAIL_HEADER = bytes([\n",
    "    0x10, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00, 0x00,\n",
    "    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00\n",
    "])\n",
    "\n",
    "DECAL_PART_DATA = {\n",
    "    \"head\": {\n",
    "        \"default_scale_bytes\": bytes.fromhex(\"3FD9999A\"),\n",
    "        \"scale_largest_bytes\": bytes.fromhex(\"3FD9999A\"),\n",
    "        \"scale_smallest_bytes\": bytes.fromhex(\"42480000\"),\n",
    "        \"min_x_at_default_bytes\": bytes.fromhex(\"BF5999A0\"),\n",
    "        \"max_x_at_default_bytes\": bytes.fromhex(\"3F599994\"),\n",
    "        \"min_y_at_default_bytes\": bytes.fromhex(\"BFA3E98D\"),\n",
    "        \"max_y_at_default_bytes\": bytes.fromhex(\"3ED6C034\"),\n",
    "        \"z_pos_bytes\": bytes.fromhex(\"C0ECFB3F\"),\n",
    "    },\n",
    "    \"core\": {\n",
    "        \"default_scale_bytes\": bytes.fromhex(\"40957074\"),\n",
    "        \"scale_largest_bytes\": bytes.fromhex(\"3FD9999A\"),\n",
    "        \"scale_smallest_bytes\": bytes.fromhex(\"42480000\"),\n",
    "        \"min_x_at_default_bytes\": bytes.fromhex(\"C015EB6E\"),\n",
    "        \"max_x_at_default_bytes\": bytes.fromhex(\"4014F57A\"),\n",
    "        \"min_y_at_default_bytes\": bytes.fromhex(\"C06FA5E4\"),\n",
    "        \"max_y_at_default_bytes\": bytes.fromhex(\"3F6CEC10\"),\n",
    "        \"z_pos_bytes\": bytes.fromhex(\"C040984F\"),\n",
    "    },\n",
    "    \"arm_right\": {\n",
    "        \"default_scale_bytes\": bytes.fromhex(\"40BDB4ED\"),\n",
    "        \"scale_largest_bytes\": bytes.fromhex(\"3FD9999A\"),\n",
    "        \"scale_smallest_bytes\": bytes.fromhex(\"42480000\"),\n",
    "        \"min_x_at_default_bytes\": bytes.fromhex(\"BFFDC2F5\"),\n",
    "        \"max_x_at_default_bytes\": bytes.fromhex(\"407C8860\"),\n",
    "        \"min_y_at_default_bytes\": bytes.fromhex(\"C016EDC3\"),\n",
    "        \"max_y_at_default_bytes\": bytes.fromhex(\"40647C17\"),\n",
    "        \"z_pos_bytes\": bytes.fromhex(\"BFD22BB2\"),\n",
    "    },\n",
    "    \"arm_left\": {\n",
    "        \"default_scale_bytes\": bytes.fromhex(\"40BDB4ED\"),\n",
    "        \"scale_largest_bytes\": bytes.fromhex(\"3FD9999A\"),\n",
    "        \"scale_smallest_bytes\": bytes.fromhex(\"42480000\"),\n",
    "        \"min_x_at_default_bytes\": bytes.fromhex(\"C0078858\"),\n",
    "        \"max_x_at_default_bytes\": bytes.fromhex(\"3FFDC303\"),\n",
    "        \"min_y_at_default_bytes\": bytes.fromhex(\"C016EDC0\"),\n",
    "        \"max_y_at_default_bytes\": bytes.fromhex(\"40647C1A\"),\n",
    "        \"z_pos_bytes\": bytes.fromhex(\"BFD22BBA\"),\n",
    "    },\n",
    "    \"legs\": {\n",
    "        \"default_scale_bytes\": bytes.fromhex(\"40DA9BED\"),\n",
    "        \"scale_largest_bytes\": bytes.fromhex(\"3FD9999A\"),\n",
    "        \"scale_smallest_bytes\": bytes.fromhex(\"42480000\"),\n",
    "        \"min_x_at_default_bytes\": bytes.fromhex(\"C05A9BE8\"),\n",
    "        \"max_x_at_default_bytes\": bytes.fromhex(\"405A9BF2\"),\n",
    "        \"min_y_at_default_bytes\": bytes.fromhex(\"3EC5B858\"),\n",
    "        \"max_y_at_default_bytes\": bytes.fromhex(\"40E6F772\"),\n",
    "        \"z_pos_bytes\": bytes.fromhex(\"3F069853\"),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_part_mapping(file_path):\n",
    "    part_mapping = {}\n",
    "    current_category = None\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "\n",
    "            # Detect category header like 'Head (0):'\n",
    "            if line.endswith('):'):\n",
    "                category_name, category_id = line[:-2].rsplit('(', 1)\n",
    "                current_category = category_name.strip()\n",
    "                part_mapping[current_category] = {}\n",
    "                continue\n",
    "\n",
    "            if current_category is None:\n",
    "                continue  # Skip any lines before first category\n",
    "\n",
    "            # Split the line into part_id and part_name\n",
    "            if ' ' in line:\n",
    "                part_id, part_name = line.split(' ', 1)\n",
    "                part_mapping[current_category][part_id.strip()\n",
    "                                               ] = part_name.strip()\n",
    "\n",
    "    return part_mapping\n",
    "\n",
    "\n",
    "part_mapping = parse_part_mapping(\"ACFA_PS3_US_PARTID_TO_PARTNAME.txt\")\n",
    "print(part_mapping.keys())\n",
    "\n",
    "BLOCK_SIZE = 24280\n",
    "NAME_SIZE = 96  # 48 wchar_t = 96 bytes in UTF-16\n",
    "\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def save_file(path, data):\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "def linear_utf16_clean_name_reader(data, start_offset, max_bytes=96):\n",
    "    raw_field = data[start_offset:start_offset + max_bytes]\n",
    "    try:\n",
    "        decoded = raw_field.decode('utf-16-le', errors='ignore').strip('\\x00')\n",
    "        match = re.match(r'^[A-Za-z0-9 ]+', decoded)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "    except UnicodeDecodeError:\n",
    "        return \"<Invalid UTF-16 Encoding>\"\n",
    "\n",
    "\n",
    "def read_timestamp(data, offset):\n",
    "    timestamp_bytes = data[offset:offset + 8]\n",
    "    return struct.unpack(\">Q\", timestamp_bytes)[0]\n",
    "\n",
    "\n",
    "def extract_active_schematic_blocks(file_path):\n",
    "    \"\"\"\n",
    "    Extracts all schematic blocks from the given file.\n",
    "    Returns a list of blocks.\n",
    "    \"\"\"\n",
    "    data = load_file(file_path)\n",
    "    schematic_count = data[5]\n",
    "    blocks = []\n",
    "    first_marker_offset = 0x148\n",
    "\n",
    "    for slot_index in range(schematic_count):\n",
    "        block_start = first_marker_offset + (slot_index * BLOCK_SIZE)\n",
    "        block = data[block_start:block_start + BLOCK_SIZE]\n",
    "        blocks.append(block)\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def display_schematic_info(block):\n",
    "    \"\"\"\n",
    "    Displays the schematic information from a block.\n",
    "    Returns a dictionary with the schematic information.\n",
    "    \"\"\"\n",
    "    schematic_name = linear_utf16_clean_name_reader(block, 1, NAME_SIZE)\n",
    "    designer_name = linear_utf16_clean_name_reader(\n",
    "        block, 1 + NAME_SIZE, NAME_SIZE)\n",
    "    timestamp = read_timestamp(block, 192)\n",
    "\n",
    "    protect_category_byte = block[200]\n",
    "    protect = (protect_category_byte & 0b10000000) >> 7\n",
    "    category = (protect_category_byte & 0b01111111) + 1\n",
    "\n",
    "    parts = extract_parts(block, part_mapping)\n",
    "    tuning = extract_tuning(block)\n",
    "\n",
    "    schematic_info = {\n",
    "        \"name\": schematic_name,\n",
    "        \"designer\": designer_name,\n",
    "        \"category\": category,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"parts\": parts,\n",
    "        \"tuning\": tuning\n",
    "    }\n",
    "\n",
    "    # Optional print for debugging\n",
    "    # print(f\"  Name: {schematic_info['name']}\")\n",
    "    # print(f\"  Designer: {schematic_info['designer']}\")\n",
    "    # print(f\"  Protect: {schematic_info['protect']}\")\n",
    "    # print(f\"  User Slot: {schematic_info['category']}\")\n",
    "    # print(f\"  Raw Byte: 0x{schematic_info['raw_byte']:02x}\")\n",
    "    # print(f\"  Timestamp: {schematic_info['timestamp']}\")\n",
    "    # print(\"  Parts:\", schematic_info['parts'])\n",
    "    # print(\"  Tuning:\", schematic_info['tuning'])\n",
    "    # print()\n",
    "\n",
    "    return schematic_info\n",
    "\n",
    "\n",
    "def extract_parts(block, part_name_lookup):\n",
    "    LOCAL_PARTS_OFFSET = 0xD8  # 0x220 - 0x148\n",
    "    PART_ENTRY_SIZE = 2\n",
    "\n",
    "    # Define lookup keys and display labels separately\n",
    "    lookup_keys = [\n",
    "        'Head', 'Core', 'Arms', 'Legs', 'FCS', 'Generator', 'Main Booster',\n",
    "        'Back Booster', 'Side Booster', 'Overed Booster',\n",
    "        'Arm Unit', 'Arm Unit', 'Back Unit', 'Back Unit', 'Shoulder Unit'\n",
    "    ]\n",
    "\n",
    "    display_labels = [\n",
    "        'Head', 'Core', 'Arms', 'Legs', 'FCS', 'Generator', 'Main Booster',\n",
    "        'Back Booster', 'Side Booster', 'Overed Booster',\n",
    "        'Right Arm Unit', 'Left Arm Unit', 'Right Back Unit',\n",
    "        'Left Back Unit', 'Shoulder Unit'\n",
    "    ]\n",
    "\n",
    "    parts_info = []\n",
    "    for i, (lookup_key, display_label) in enumerate(zip(lookup_keys, display_labels)):\n",
    "        offset = LOCAL_PARTS_OFFSET + i * PART_ENTRY_SIZE\n",
    "        part_id_bytes = block[offset:offset + PART_ENTRY_SIZE]\n",
    "\n",
    "        if len(part_id_bytes) != 2:\n",
    "            part_id_str = \"<Invalid>\"\n",
    "            part_name = \"<Invalid>\"\n",
    "        else:\n",
    "            part_id_num = int.from_bytes(part_id_bytes, byteorder='big')\n",
    "            part_id_str = f\"{part_id_num:04d}\"\n",
    "            part_name = part_name_lookup.get(lookup_key, {}).get(\n",
    "                part_id_str, f\"Unknown ID {part_id_str}\")\n",
    "\n",
    "        parts_info.append({\n",
    "            \"category\": display_label,\n",
    "            \"part_id\": part_id_str,\n",
    "            \"part_name\": part_name\n",
    "        })\n",
    "\n",
    "    return parts_info\n",
    "\n",
    "\n",
    "def extract_tuning(block):\n",
    "    LOCAL_TUNING_OFFSET = 0x126  # 0x26E - 0x148\n",
    "    TUNING_SIZE = 32  # 0x20 bytes\n",
    "\n",
    "    tuning_labels = [\n",
    "        'en_output',\n",
    "        'en_capacity',\n",
    "        'kp_output',\n",
    "        'load',\n",
    "        'en_weapon_skill',\n",
    "        'maneuverability',\n",
    "        'firing_stability',\n",
    "        'aim_precision',\n",
    "        'lock_speed',\n",
    "        'missile_lock_speed',\n",
    "        'radar_refresh_rate',\n",
    "        'ecm_resistance',\n",
    "        'rectification_head',\n",
    "        'rectification_core',\n",
    "        'rectification_arm',\n",
    "        'rectification_leg',\n",
    "        'horizontal_thrust_main',\n",
    "        'vertical_thrust',\n",
    "        'horizontal_thrust_side',\n",
    "        'horizontal_thrust_back',\n",
    "        'quick_boost_main',\n",
    "        'quick_boost_side',\n",
    "        'quick_boost_back',\n",
    "        'quick_boost_overed',\n",
    "        'turning_ability',\n",
    "        'stability_head',\n",
    "        'stability_core',\n",
    "        'stability_legs',\n",
    "    ]\n",
    "\n",
    "    tuning_values = {}\n",
    "    for i, label in enumerate(tuning_labels):\n",
    "        value = block[LOCAL_TUNING_OFFSET + i]\n",
    "        tuning_values[label] = value  # Value should be in range 0-50\n",
    "\n",
    "    return tuning_values\n",
    "\n",
    "def extract_color_data(schematic_block: bytes) -> Tuple[bytearray, bytearray, bytearray]:\n",
    "    \"\"\"\n",
    "    Extracts color, pattern, and eye color data from a schematic block.\n",
    "\n",
    "    The function calculates the local offsets for each data type based on their\n",
    "    known absolute positions in the save file and returns them as mutable\n",
    "    bytearrays.\n",
    "\n",
    "    Args:\n",
    "        schematic_block: A bytes object representing a single schematic block.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing three bytearrays:\n",
    "        1. The main color data block (0x330 bytes).\n",
    "        2. The pattern data block (0x24 bytes).\n",
    "        3. The eye color data (0x4 bytes).\n",
    "    \"\"\"\n",
    "    # Absolute address of the first schematic block in DESDOC.DAT\n",
    "    SCHEMATIC_START_ABS = 0x148\n",
    "\n",
    "    # --- Calculate Local Offsets ---\n",
    "    # Colors: 0x290 (absolute) - 0x148 (schematic start) = 0x148 (local)\n",
    "    COLORS_LOCAL_OFFSET = 0x148\n",
    "    COLORS_SIZE = 0x330\n",
    "\n",
    "    # Patterns: 0x5C0 (absolute) - 0x148 (schematic start) = 0x478 (local)\n",
    "    PATTERNS_LOCAL_OFFSET = 0x478\n",
    "    PATTERNS_SIZE = 0x24\n",
    "\n",
    "    # Eye Color: 0x5E4 (absolute) - 0x148 (schematic start) = 0x49C (local)\n",
    "    EYE_COLOR_LOCAL_OFFSET = 0x49C\n",
    "    EYE_COLOR_SIZE = 0x4\n",
    "\n",
    "    # --- Extract Data Blocks ---\n",
    "    colors_data = schematic_block[COLORS_LOCAL_OFFSET:COLORS_LOCAL_OFFSET + COLORS_SIZE]\n",
    "    patterns_data = schematic_block[PATTERNS_LOCAL_OFFSET:PATTERNS_LOCAL_OFFSET + PATTERNS_SIZE]\n",
    "    eye_color_data = schematic_block[EYE_COLOR_LOCAL_OFFSET:EYE_COLOR_LOCAL_OFFSET + EYE_COLOR_SIZE]\n",
    "\n",
    "    # Return as mutable bytearrays\n",
    "    return bytearray(colors_data), bytearray(patterns_data), bytearray(eye_color_data)\n",
    "\n",
    "\n",
    "def replace_color_data(\n",
    "    schematic_block: bytes,\n",
    "    new_colors: bytes | None = None,\n",
    "    new_patterns: bytes | None = None,\n",
    "    new_eye_color: bytes | None = None\n",
    ") -> bytes:\n",
    "    \"\"\"\n",
    "    Replaces specified color, pattern, or eye color data in a schematic block.\n",
    "\n",
    "    If a replacement is not provided for a specific data block (i.e., the\n",
    "    argument is None), the original data from the schematic_block is kept.\n",
    "\n",
    "    Args:\n",
    "        schematic_block: The original schematic block bytes.\n",
    "        new_colors: Optional new color data (must be 0x330 bytes if provided).\n",
    "        new_patterns: Optional new pattern data (must be 0x24 bytes if provided).\n",
    "        new_eye_color: Optional new eye color data (must be 0x4 bytes if provided).\n",
    "\n",
    "    Returns:\n",
    "        A new schematic block bytes object with the specified data replaced.\n",
    "    \"\"\"\n",
    "    # Define constants for offsets and sizes\n",
    "    COLORS_LOCAL_OFFSET = 0x148\n",
    "    COLORS_SIZE = 0x330\n",
    "    PATTERNS_LOCAL_OFFSET = 0x478\n",
    "    PATTERNS_SIZE = 0x24\n",
    "    EYE_COLOR_LOCAL_OFFSET = 0x49C\n",
    "    EYE_COLOR_SIZE = 0x4\n",
    "\n",
    "    mutable_block = bytearray(schematic_block)\n",
    "\n",
    "    # --- Conditionally Replace Data ---\n",
    "    if new_colors is not None:\n",
    "        if len(new_colors) != COLORS_SIZE:\n",
    "            raise ValueError(\n",
    "                f\"Invalid colors data size. Expected {COLORS_SIZE}, got {len(new_colors)}.\")\n",
    "        mutable_block[COLORS_LOCAL_OFFSET:COLORS_LOCAL_OFFSET +\n",
    "                      COLORS_SIZE] = new_colors\n",
    "\n",
    "    if new_patterns is not None:\n",
    "        if len(new_patterns) != PATTERNS_SIZE:\n",
    "            raise ValueError(\n",
    "                f\"Invalid patterns data size. Expected {PATTERNS_SIZE}, got {len(new_patterns)}.\")\n",
    "        mutable_block[PATTERNS_LOCAL_OFFSET:PATTERNS_LOCAL_OFFSET +\n",
    "                      PATTERNS_SIZE] = new_patterns\n",
    "\n",
    "    if new_eye_color is not None:\n",
    "        if len(new_eye_color) != EYE_COLOR_SIZE:\n",
    "            raise ValueError(\n",
    "                f\"Invalid eye color data size. Expected {EYE_COLOR_SIZE}, got {len(new_eye_color)}.\")\n",
    "        mutable_block[EYE_COLOR_LOCAL_OFFSET:EYE_COLOR_LOCAL_OFFSET +\n",
    "                      EYE_COLOR_SIZE] = new_eye_color\n",
    "\n",
    "    return bytes(mutable_block)\n",
    "\n",
    "\n",
    "def randomize_colors(colors_data: bytes) -> bytes:\n",
    "    \"\"\"\n",
    "    Randomizes the RGB channels for all colors in a color data block.\n",
    "\n",
    "    The alpha channel of each color is preserved as it is unused in-game.\n",
    "\n",
    "    Args:\n",
    "        colors_data: The color data block (e.g., 0x330 bytes).\n",
    "\n",
    "    Returns:\n",
    "        A new color data block with randomized RGB values.\n",
    "    \"\"\"\n",
    "    if len(colors_data) % 4 != 0:\n",
    "        raise ValueError(\n",
    "            \"Invalid colors data length. Length must be divisible by 4.\")\n",
    "\n",
    "    mutable_colors = bytearray(colors_data)\n",
    "\n",
    "    # Iterate through each color (4 bytes at a time)\n",
    "    for i in range(0, len(mutable_colors), 4):\n",
    "        # Randomize R, G, B channels\n",
    "        mutable_colors[i] = random.randint(0, 255)   # R\n",
    "        mutable_colors[i+1] = random.randint(0, 255)  # G\n",
    "        mutable_colors[i+2] = random.randint(0, 255)  # B\n",
    "        # The 4th byte (alpha) at i+3 is intentionally left unchanged.\n",
    "\n",
    "    return bytes(mutable_colors)\n",
    "\n",
    "\n",
    "def extract_decal_data(schematic_block: bytes) -> bytearray:\n",
    "    \"\"\"\n",
    "    Extracts decal data from a schematic block.\n",
    "\n",
    "    The function calculates the local offset for the decal data based on its\n",
    "    known absolute position in the save file and returns it as a mutable\n",
    "    bytearray.\n",
    "\n",
    "    Args:\n",
    "        schematic_block: A bytes object representing a single schematic block.\n",
    "\n",
    "    Returns:\n",
    "        A bytearray containing the decal data (0x19A0 bytes).\n",
    "    \"\"\"\n",
    "    # Absolute address of the first schematic block in DESDOC.DAT\n",
    "    SCHEMATIC_START_ABS = 0x148\n",
    "\n",
    "    # Decals: 0x5E8 (absolute) - 0x148 (schematic start) = 0x4A0 (local)\n",
    "    DECAL_DATA_LOCAL_OFFSET = 0x4A0\n",
    "    DECAL_DATA_SIZE = 0x19A0\n",
    "\n",
    "    # --- Extract Data Block ---\n",
    "    decal_data = schematic_block[DECAL_DATA_LOCAL_OFFSET:\n",
    "                                 DECAL_DATA_LOCAL_OFFSET + DECAL_DATA_SIZE]\n",
    "\n",
    "    # Return as a mutable bytearray\n",
    "    return bytearray(decal_data)\n",
    "\n",
    "\n",
    "def replace_decal_data(\n",
    "    schematic_block: bytes,\n",
    "    new_decal_data: bytes\n",
    ") -> bytes:\n",
    "    \"\"\"\n",
    "    Replaces the decal data in a schematic block.\n",
    "\n",
    "    Args:\n",
    "        schematic_block: The original schematic block bytes.\n",
    "        new_decal_data: New decal data (must be 0x19A0 bytes).\n",
    "\n",
    "    Returns:\n",
    "        A new schematic block bytes object with the decal data replaced.\n",
    "    \"\"\"\n",
    "    # Define constants for offset and size\n",
    "    DECAL_DATA_LOCAL_OFFSET = 0x4A0\n",
    "    DECAL_DATA_SIZE = 0x19A0\n",
    "\n",
    "    if len(new_decal_data) != DECAL_DATA_SIZE:\n",
    "        raise ValueError(\n",
    "            f\"Invalid decal data size. Expected {DECAL_DATA_SIZE}, got {len(new_decal_data)}.\")\n",
    "\n",
    "    mutable_block = bytearray(schematic_block)\n",
    "    mutable_block[DECAL_DATA_LOCAL_OFFSET:DECAL_DATA_LOCAL_OFFSET +\n",
    "                  DECAL_DATA_SIZE] = new_decal_data\n",
    "\n",
    "    return bytes(mutable_block)\n",
    "\n",
    "\n",
    "def parse_emblem_data(data: bytes):\n",
    "    \"\"\"\n",
    "    Parses a 132-byte emblem data block into a structured dictionary.\n",
    "\n",
    "    Args:\n",
    "        data: A bytes object of length 132 (0x84).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the emblem's type and a list of 16 layers,\n",
    "        with each layer's properties parsed into a human-readable format.\n",
    "        Returns None if the data length is incorrect.\n",
    "    \"\"\"\n",
    "    if len(data) != 132:\n",
    "        raise ValueError(\n",
    "            f\"Invalid data length. Expected 132 bytes, got {len(data)}.\")\n",
    "\n",
    "    emblem_info = {\n",
    "        'type': data[0],\n",
    "        'unknown_header': data[1:4].hex(),\n",
    "        'layers': []\n",
    "    }\n",
    "\n",
    "    layers_data = data[4:]\n",
    "\n",
    "    for i in range(16):\n",
    "        offset = i * 8\n",
    "        layer_bytes = layers_data[offset:offset + 8]\n",
    "\n",
    "        if len(layer_bytes) < 8:\n",
    "            # Avoids index out of range if data is malformed\n",
    "            continue\n",
    "\n",
    "        flags = layer_bytes[7]\n",
    "\n",
    "        layer_info = {\n",
    "            'layer_index': i,\n",
    "            'angle': layer_bytes[0],\n",
    "            'image_id': layer_bytes[1],\n",
    "            'color': layer_bytes[2],\n",
    "            'width': layer_bytes[3],\n",
    "            'height': layer_bytes[4],\n",
    "            'x_position': layer_bytes[5],\n",
    "            'y_position': layer_bytes[6],\n",
    "            'flags': {\n",
    "                'raw_byte': f\"0x{flags:02x}\",\n",
    "                'negative_angle': bool((flags >> 4) & 1),\n",
    "                'negative_x': bool((flags >> 6) & 1),\n",
    "                'negative_y': bool((flags >> 7) & 1),\n",
    "            }\n",
    "        }\n",
    "        emblem_info['layers'].append(layer_info)\n",
    "\n",
    "    return emblem_info\n",
    "\n",
    "\n",
    "def parse_paint_dat(file_path: str) -> list[bytes]:\n",
    "    \"\"\"\n",
    "    Parses the PAINT.DAT file to extract existing emblem data blocks.\n",
    "\n",
    "    Emblems start at offset 0x214. Each emblem is 132 bytes (0x84) long.\n",
    "    There are 64 possible emblem slots. Parsing stops when an emblem's\n",
    "    first byte is 0x00, indicating a non-existent emblem.\n",
    "\n",
    "    Args:\n",
    "        file_path: The absolute path to the PAINT.DAT file.\n",
    "\n",
    "    Returns:\n",
    "        A list of bytes objects, where each bytes object is a 132-byte\n",
    "        emblem data block.\n",
    "    \"\"\"\n",
    "    EMBLEM_START_OFFSET = 0x214\n",
    "    EMBLEM_SIZE = 132  # 0x84 bytes\n",
    "    NUM_EMBLEM_SLOTS = 64\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            paint_data = f.read()\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"PAINT.DAT not found at {file_path}\")\n",
    "\n",
    "    emblems = []\n",
    "    for i in range(NUM_EMBLEM_SLOTS):\n",
    "        current_emblem_offset = EMBLEM_START_OFFSET + (i * EMBLEM_SIZE)\n",
    "\n",
    "        # Ensure there's enough data to read at least the first byte of an emblem\n",
    "        if current_emblem_offset >= len(paint_data):\n",
    "            break\n",
    "\n",
    "        # Check if the emblem exists (first byte is not 0x00)\n",
    "        if paint_data[current_emblem_offset] == 0x00:\n",
    "            break  # Stop parsing if a non-existent emblem is found\n",
    "\n",
    "        # Extract the full emblem data block\n",
    "        emblem_data = paint_data[current_emblem_offset:\n",
    "                                 current_emblem_offset + EMBLEM_SIZE]\n",
    "\n",
    "        # Ensure the extracted block is the correct size\n",
    "        if len(emblem_data) == EMBLEM_SIZE:\n",
    "            emblems.append(emblem_data)\n",
    "        else:\n",
    "            # This case should ideally not happen if the file is well-formed\n",
    "            # and the previous length check passed, but good for robustness.\n",
    "            print(\n",
    "                f\"Warning: Incomplete emblem data found at slot {i}. Skipping.\")\n",
    "            break  # Stop if an incomplete emblem is found\n",
    "\n",
    "    return emblems\n",
    "\n",
    "\n",
    "def generate_random_emblem(num_layers: int | None = None) -> bytes:\n",
    "    \"\"\"\n",
    "    Generates a random 132-byte emblem data block adhering to game limitations.\n",
    "\n",
    "    Args:\n",
    "        num_layers: Optional. The number of layers to generate (1-16). If None,\n",
    "                    a random number of layers will be generated.\n",
    "\n",
    "    Returns:\n",
    "        A bytes object representing a randomly generated emblem.\n",
    "    \"\"\"\n",
    "    EMBLEM_SIZE = 132  # 0x84 bytes\n",
    "    emblem_data = bytearray(EMBLEM_SIZE)\n",
    "\n",
    "    # Header (4 bytes)\n",
    "    emblem_data[0] = 0x02  # Type: custom emblem\n",
    "    emblem_data[1:4] = bytes([0x00, 0x00, 0x00])  # Unknown, always 0\n",
    "\n",
    "    # Valid image IDs from documentation\n",
    "    valid_image_ids = []\n",
    "    for r in [(0, 20), (29, 60), (69, 88), (97, 112), (121, 144), (149, 164), (173, 188), (205, 252)]:\n",
    "        valid_image_ids.extend(range(r[0], r[1] + 1))\n",
    "\n",
    "    if num_layers is None:\n",
    "        actual_num_layers = random.randint(1, 16)\n",
    "    elif 1 <= num_layers <= 16:\n",
    "        actual_num_layers = num_layers\n",
    "    else:\n",
    "        raise ValueError(\"num_layers must be between 1 and 16, or None.\")\n",
    "\n",
    "    # Layers (8 bytes each)\n",
    "    for i in range(actual_num_layers):\n",
    "        layer_offset = 4 + (i * 8)\n",
    "\n",
    "        # byte 0 : angle (0-180 decimal)\n",
    "        emblem_data[layer_offset] = random.randint(0, 180)\n",
    "\n",
    "        # byte 1 : image id\n",
    "        emblem_data[layer_offset + 1] = random.choice(valid_image_ids)\n",
    "\n",
    "        # byte 2 : color (0-7 decimal)\n",
    "        emblem_data[layer_offset + 2] = random.randint(0, 7)\n",
    "\n",
    "        # byte 3 : width (1-127 decimal)\n",
    "        emblem_data[layer_offset + 3] = random.randint(1, 127)\n",
    "\n",
    "        # byte 4 : height (1-127 decimal)\n",
    "        emblem_data[layer_offset + 4] = random.randint(1, 127)\n",
    "\n",
    "        # byte 5 : x position (0-255 decimal)\n",
    "        emblem_data[layer_offset + 5] = random.randint(0, 255)\n",
    "\n",
    "        # byte 6 : y position (0-255 decimal)\n",
    "        emblem_data[layer_offset + 6] = random.randint(0, 255)\n",
    "\n",
    "        # byte 7 : flags\n",
    "        flags = 0\n",
    "        # bit 0 - 3 : unknown, always 0\n",
    "        # bit 4 : negative angle (0 or 1)\n",
    "        flags |= (random.randint(0, 1) << 4)\n",
    "        # bit 5 : unknown, always 0\n",
    "        # bit 6 : negative x (0 or 1)\n",
    "        flags |= (random.randint(0, 1) << 6)\n",
    "        # bit 7 : negative y (0 or 1)\n",
    "        flags |= (random.randint(0, 1) << 7)\n",
    "        emblem_data[layer_offset + 7] = flags\n",
    "\n",
    "    # Fill remaining layers with zeros if actual_num_layers < 16\n",
    "    for i in range(actual_num_layers, 16):\n",
    "        layer_offset = 4 + (i * 8)\n",
    "        emblem_data[layer_offset:layer_offset + 8] = bytes([0] * 8)\n",
    "\n",
    "    return bytes(emblem_data)\n",
    "\n",
    "\n",
    "\n",
    "def append_emblem_to_paint_dat(file_path: str, new_emblem_data: bytes):\n",
    "    \"\"\"\n",
    "    Appends a new emblem to the PAINT.DAT file by replacing the first empty slot.\n",
    "\n",
    "    Args:\n",
    "        file_path: The absolute path to the PAINT.DAT file.\n",
    "        new_emblem_data: A bytes object representing the new emblem (must be 132 bytes).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If new_emblem_data is not 132 bytes long.\n",
    "        FileNotFoundError: If PAINT.DAT is not found.\n",
    "        RuntimeError: If no empty emblem slot is found in PAINT.DAT.\n",
    "    \"\"\"\n",
    "    EMBLEM_START_OFFSET = 0x214\n",
    "    EMBLEM_SIZE = 132  # 0x84 bytes\n",
    "    NUM_EMBLEM_SLOTS = 64\n",
    "\n",
    "    if len(new_emblem_data) != EMBLEM_SIZE:\n",
    "        raise ValueError(\n",
    "            f\"New emblem data must be {EMBLEM_SIZE} bytes long, got {len(new_emblem_data)}.\")\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            paint_data = bytearray(f.read())\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"PAINT.DAT not found at {file_path}\")\n",
    "\n",
    "    found_empty_slot = False\n",
    "    for i in range(NUM_EMBLEM_SLOTS):\n",
    "        current_emblem_offset = EMBLEM_START_OFFSET + (i * EMBLEM_SIZE)\n",
    "\n",
    "        # Ensure there's enough space in the file for this slot\n",
    "        if current_emblem_offset + EMBLEM_SIZE > len(paint_data):\n",
    "            # If we run out of file before finding an empty slot, it's an issue\n",
    "            raise RuntimeError(\n",
    "                \"PAINT.DAT file is too short or corrupted, no space for new emblem.\")\n",
    "\n",
    "        # Check if the emblem slot is empty (first byte is 0x00)\n",
    "        if paint_data[current_emblem_offset] == 0x00:\n",
    "            # Replace the empty slot with the new emblem data\n",
    "            paint_data[current_emblem_offset:current_emblem_offset +\n",
    "                       EMBLEM_SIZE] = new_emblem_data\n",
    "            found_empty_slot = True\n",
    "            break\n",
    "\n",
    "    if not found_empty_slot:\n",
    "        raise RuntimeError(\n",
    "            \"No empty emblem slots found in PAINT.DAT. File is full.\")\n",
    "\n",
    "    # Save the modified PAINT.DAT file\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(paint_data)\n",
    "\n",
    "\n",
    "def generate_random_decal_layer(part_type: str, current_scale_bytes: bytes | None = None) -> bytes:\n",
    "    \"\"\"\n",
    "    Generates a single, random, and valid 164-byte decal layer.\n",
    "\n",
    "    Args:\n",
    "        part_type: The type of part, e.g., \"head\", \"core\", \"arm_right\", \"arm_left\", \"legs\".\n",
    "        current_scale_bytes: Optional. The 4-byte float representation of the current scale.\n",
    "                             If None, a random scale for the part will be generated.\n",
    "\n",
    "    Returns:\n",
    "        A 164-byte `bytes` object representing a complete decal layer.\n",
    "    \"\"\"\n",
    "    if part_type not in DECAL_PART_DATA:\n",
    "        raise ValueError(\n",
    "            f\"Invalid part_type. Must be one of {list(DECAL_PART_DATA.keys())}\")\n",
    "\n",
    "    part_data = DECAL_PART_DATA[part_type]\n",
    "    layer_data = bytearray(164)\n",
    "\n",
    "    # 1. Emblem (132 bytes)\n",
    "    layer_data[0:132] = generate_random_emblem()\n",
    "\n",
    "    # 2. Width and Height (1 byte each)\n",
    "    layer_data[132] = random.randint(3, 255)\n",
    "    layer_data[133] = random.randint(3, 255)\n",
    "\n",
    "    # 3. Unknown (2 bytes)\n",
    "    layer_data[134:136] = bytes([0, 0])\n",
    "\n",
    "    # 4. Rotation (12 bytes)\n",
    "    for i in range(3):\n",
    "        rand_rot_float = random.uniform(-math.pi, math.pi)\n",
    "        print(f\"rand_rot_float axis {i}: {rand_rot_float}\")\n",
    "        layer_data[136 + i*4: 136 +\n",
    "                   (i+1)*4] = struct.pack('<f', rand_rot_float)\n",
    "        print(f'')\n",
    "\n",
    "    # 5. Scale (4 bytes) - Must be determined before position\n",
    "    if current_scale_bytes is None:\n",
    "        scale_largest_float = struct.unpack(\n",
    "            '>f', part_data[\"scale_largest_bytes\"])[0]\n",
    "        scale_smallest_float = struct.unpack(\n",
    "            '>f', part_data[\"scale_smallest_bytes\"])[0]\n",
    "        rand_scale_float = random.uniform(\n",
    "            scale_largest_float, scale_smallest_float)\n",
    "        final_scale_bytes = struct.pack('<f', rand_scale_float)\n",
    "    else:\n",
    "        final_scale_bytes = current_scale_bytes\n",
    "\n",
    "    layer_data[160:164] = final_scale_bytes\n",
    "\n",
    "    # 6. Position (12 bytes) - Dependent on scale\n",
    "    # Unpack floats from bytes for calculation\n",
    "    default_scale = struct.unpack('<f', part_data[\"default_scale_bytes\"])[0]\n",
    "    current_scale = struct.unpack('<f', final_scale_bytes)[0]\n",
    "    print(f\"current_scale: {current_scale}\")\n",
    "\n",
    "    # Calculate boundary constants for X and Y\n",
    "    min_x_at_default = struct.unpack(\n",
    "        '>f', part_data[\"min_x_at_default_bytes\"])[0]\n",
    "    max_x_at_default = struct.unpack(\n",
    "        '>f', part_data[\"max_x_at_default_bytes\"])[0]\n",
    "    min_y_at_default = struct.unpack(\n",
    "        '>f', part_data[\"min_y_at_default_bytes\"])[0]\n",
    "    max_y_at_default = struct.unpack(\n",
    "        '>f', part_data[\"max_y_at_default_bytes\"])[0]\n",
    "\n",
    "    const_min_x = min_x_at_default * default_scale\n",
    "    const_max_x = max_x_at_default * default_scale\n",
    "    const_min_y = min_y_at_default * default_scale\n",
    "    const_max_y = max_y_at_default * default_scale\n",
    "\n",
    "    # Calculate dynamic range for the current scale\n",
    "    current_min_x = const_min_x / current_scale\n",
    "    current_max_x = const_max_x / current_scale\n",
    "    current_min_y = const_min_y / current_scale\n",
    "    current_max_y = const_max_y / current_scale\n",
    "    print(f\"current_min_x: {current_min_x}\")\n",
    "    print(f\"current_max_x: {current_max_x}\")\n",
    "    print(f\"current_min_y: {current_min_y}\")\n",
    "    print(f\"current_max_y: {current_max_y}\")\n",
    "\n",
    "    # Generate random floats within the dynamic range and pack them\n",
    "    rand_pos_x = random.uniform(current_min_x, current_max_x)\n",
    "    print(f\"rand_pos_x: {rand_pos_x}\")\n",
    "    rand_pos_y = random.uniform(current_min_y, current_max_y)\n",
    "    print(f\"rand_pos_y: {rand_pos_y}\")\n",
    "\n",
    "    layer_data[148:152] = struct.pack('<f', rand_pos_x)\n",
    "    layer_data[152:156] = struct.pack('<f', rand_pos_y)\n",
    "    layer_data[156:160] = part_data[\"z_pos_bytes\"]\n",
    "\n",
    "    return bytes(layer_data)\n",
    "\n",
    "\n",
    "def biased_scale(min_val=1.7, max_val=50, exponent=2.0):\n",
    "    \"\"\"\n",
    "    Generate a float between min_val and max_val, biased toward min_val.\n",
    "    exponent > 1 increases bias toward smaller numbers.\n",
    "    exponent = 1 gives uniform distribution.\n",
    "    \"\"\"\n",
    "    u = random.random()  # uniform 0..1\n",
    "    biased = min_val + (max_val - min_val) * (u ** exponent)\n",
    "    return biased\n",
    "\n",
    "\n",
    "\n",
    "def generate_random_decal_layer_alt(part_type: str, current_scale_bytes: bytes | None = None) -> bytes:\n",
    "    \"\"\"\n",
    "    Generates a single, random, and valid 164-byte decal layer.\n",
    "\n",
    "    Coordinates (x, y) are restricted to default-scale min/max to avoid invalid values.\n",
    "    Scale can still vary independently.\n",
    "\n",
    "    Args:\n",
    "        part_type: \"head\", \"core\", \"arm_right\", \"arm_left\", \"legs\".\n",
    "        current_scale_bytes: Optional 4-byte float for scale. If None, a random scale is generated.\n",
    "\n",
    "    Returns:\n",
    "        164-byte bytes object representing one decal layer.\n",
    "    \"\"\"\n",
    "    if part_type not in DECAL_PART_DATA:\n",
    "        raise ValueError(\n",
    "            f\"Invalid part_type. Must be one of {list(DECAL_PART_DATA.keys())}\")\n",
    "\n",
    "    part_data = DECAL_PART_DATA[part_type]\n",
    "    layer_data = bytearray(164)\n",
    "\n",
    "    # 1. Emblem (132 bytes)\n",
    "    layer_data[0:132] = generate_random_emblem()\n",
    "\n",
    "    # 2. Width and Height (1 byte each)\n",
    "    layer_data[132] = random.randint(3, 255)\n",
    "    layer_data[133] = random.randint(3, 255)\n",
    "\n",
    "    # 3. Unknown (2 bytes)\n",
    "    layer_data[134:136] = bytes([0, 0])\n",
    "\n",
    "    # 4. Rotation (12 bytes)\n",
    "    for i in range(3):\n",
    "        rand_rot_float = random.uniform(-math.pi, math.pi)\n",
    "        print(f\"rand_rot_float axis {i}: {rand_rot_float}\")\n",
    "        layer_data[136 + i*4: 140 + i*4] = struct.pack('>f', rand_rot_float)\n",
    "\n",
    "    # 5. Scale (4 bytes)\n",
    "    if current_scale_bytes is None:\n",
    "        scale_largest = struct.unpack(\n",
    "            '>f', part_data[\"scale_largest_bytes\"])[0]\n",
    "        scale_smallest = struct.unpack(\n",
    "            '>f', part_data[\"scale_smallest_bytes\"])[0]\n",
    "        rand_scale_float = biased_scale(\n",
    "            scale_largest, scale_smallest, exponent=5.0)\n",
    "        final_scale_bytes = struct.pack('>f', rand_scale_float)\n",
    "    else:\n",
    "        final_scale_bytes = current_scale_bytes\n",
    "    layer_data[160:164] = final_scale_bytes\n",
    "\n",
    "    # 6. Position (12 bytes) — clamp to default-scale ranges\n",
    "    min_x = struct.unpack('>f', part_data[\"min_x_at_default_bytes\"])[0]\n",
    "    max_x = struct.unpack('>f', part_data[\"max_x_at_default_bytes\"])[0]\n",
    "    min_y = struct.unpack('>f', part_data[\"min_y_at_default_bytes\"])[0]\n",
    "    max_y = struct.unpack('>f', part_data[\"max_y_at_default_bytes\"])[0]\n",
    "\n",
    "    rand_pos_x = random.uniform(min_x, max_x)\n",
    "    rand_pos_y = random.uniform(min_y, max_y)\n",
    "\n",
    "    layer_data[148:152] = struct.pack('>f', rand_pos_x)\n",
    "    layer_data[152:156] = struct.pack('>f', rand_pos_y)\n",
    "\n",
    "    # 7. Z position (4 bytes)\n",
    "    layer_data[156:160] = part_data[\"z_pos_bytes\"]\n",
    "\n",
    "    return bytes(layer_data)\n",
    "\n",
    "\n",
    "\n",
    "def generate_random_decal_section(part_type: str, current_scale_bytes: bytes | None = None) -> bytes:\n",
    "    \"\"\"\n",
    "    Generates a complete, random 1312-byte (0x520) decal section for a given part type.\n",
    "\n",
    "    A decal section consists of 8 individual decal layers.\n",
    "\n",
    "    Args:\n",
    "        part_type: The type of part, e.g., \"head\", \"core\", \"arm_right\", \"arm_left\", \"legs\".\n",
    "        current_scale_bytes: Optional. The 4-byte float representation of the current scale.\n",
    "                             If None, a random scale for the part will be generated for each layer.\n",
    "\n",
    "    Returns:\n",
    "        A 1312-byte `bytes` object representing a complete decal section.\n",
    "    \"\"\"\n",
    "    if part_type not in DECAL_PART_DATA:\n",
    "        raise ValueError(\n",
    "            f\"Invalid part_type. Must be one of {list(DECAL_PART_DATA.keys())}\")\n",
    "\n",
    "    decal_section_data = bytearray()\n",
    "    for i in range(8):  # 8 layers per section\n",
    "        print(f\"Generating layer {i+1}/8 for part '{part_type}'\")\n",
    "        decal_section_data.extend(\n",
    "            generate_random_decal_layer_alt(part_type, current_scale_bytes))\n",
    "\n",
    "    return bytes(decal_section_data)\n",
    "\n",
    "\n",
    "def generate_full_random_decal_data() -> bytes:\n",
    "    \"\"\"\n",
    "    Generates a full random decal data block (0x19A0 bytes) for all parts.\n",
    "\n",
    "    Returns:\n",
    "        A bytes object representing the complete decal data for all parts.\n",
    "    \"\"\"\n",
    "    full_decal_data = bytearray()\n",
    "\n",
    "    for part in [\"head\", \"core\", \"arm_right\", \"arm_left\", \"legs\"]:\n",
    "        section_data = generate_random_decal_section(part)\n",
    "        full_decal_data.extend(section_data)\n",
    "\n",
    "    return bytes(full_decal_data)\n",
    "\n",
    "\n",
    "def extract_thumbnail(schematic_block: bytes) -> bytes:\n",
    "    \"\"\"\n",
    "    Extracts the thumbnail data from a given schematic block.\n",
    "\n",
    "    The schematic block is a chunk of data representing one schematic\n",
    "    from the DESDOC.DAT file. This function isolates and returns the\n",
    "    raw thumbnail data from within that block.\n",
    "\n",
    "    Args:\n",
    "        schematic_block: A bytes object representing a single schematic block.\n",
    "\n",
    "    Returns:\n",
    "        A bytes object containing the full thumbnail data (header and image).\n",
    "    \"\"\"\n",
    "    # The absolute start of the first schematic is 0x148.\n",
    "    # The absolute start of the first thumbnail is 0x200C.\n",
    "    # The local offset is the difference: 0x200C - 0x148 = 0x1EC4.\n",
    "    THUMBNAIL_LOCAL_OFFSET = 0x1EC4\n",
    "\n",
    "    # The total size of the thumbnail data is 0x4010 bytes\n",
    "    # (0x10 header + 0x4000 image data).\n",
    "    THUMBNAIL_SIZE = 0x4010\n",
    "\n",
    "    # Slice the block to get the thumbnail data\n",
    "    thumbnail_data = schematic_block[THUMBNAIL_LOCAL_OFFSET:\n",
    "                                     THUMBNAIL_LOCAL_OFFSET + THUMBNAIL_SIZE]\n",
    "\n",
    "    return thumbnail_data\n",
    "\n",
    "\n",
    "def bytes_to_image(thumbnail_bytes: bytes) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Converts raw ACFA thumbnail bytes into a Pillow Image object.\n",
    "\n",
    "    Args:\n",
    "        thumbnail_bytes: The 16400 bytes (0x4010) of thumbnail data.\n",
    "\n",
    "    Returns:\n",
    "        A Pillow Image object.\n",
    "    \"\"\"\n",
    "    if len(thumbnail_bytes) != 0x4010:\n",
    "        raise ValueError(\"Thumbnail data must be 0x4010 bytes long.\")\n",
    "\n",
    "    # The actual image data starts after the 16-byte header.\n",
    "    dxt1_data = thumbnail_bytes[0x10:]\n",
    "\n",
    "    # We need to construct a valid DDS header to make this readable by Pillow.\n",
    "    # DDS header is 128 bytes.\n",
    "    dds_header = bytearray(128)\n",
    "    struct.pack_into('<4sI', dds_header, 0, b'DDS ', 124)  # Magic, Size\n",
    "    # Flags\n",
    "    struct.pack_into('<I', dds_header, 8, 0x1 | 0x2 | 0x4 | 0x1000 | 0x80000)\n",
    "    struct.pack_into('<I', dds_header, 12, 128)  # Height\n",
    "    struct.pack_into('<I', dds_header, 16, 256)  # Width\n",
    "    struct.pack_into('<I', dds_header, 20, 16384)  # LinearSize\n",
    "    # PixelFormat Sub-structure\n",
    "    struct.pack_into('<I', dds_header, 76, 32)  # PixelFormat Size\n",
    "    struct.pack_into('<I', dds_header, 80, 0x4)  # PixelFormat Flags (FourCC)\n",
    "    struct.pack_into('<4s', dds_header, 84, b'DXT1')  # FourCC\n",
    "    # Caps\n",
    "    struct.pack_into('<I', dds_header, 108, 0x1000)  # DDSCAPS_TEXTURE\n",
    "\n",
    "    dds_data = bytes(dds_header) + dxt1_data\n",
    "\n",
    "    # Use an in-memory buffer to read the DDS data\n",
    "    buffer = io.BytesIO(dds_data)\n",
    "    image = Image.open(buffer)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_to_bytes(image: Image.Image) -> bytes:\n",
    "    \"\"\"\n",
    "    Converts a Pillow Image object back into raw ACFA thumbnail bytes\n",
    "    using the Wand/ImageMagick library for reliable compression.\n",
    "    \"\"\"\n",
    "    if image.size != (256, 128):\n",
    "        raise ValueError(\"Image must be 256x128 pixels.\")\n",
    "\n",
    "    # Convert the Pillow Image to a raw byte buffer (RGBA)\n",
    "    img_rgba_bytes = image.convert('RGBA').tobytes()\n",
    "\n",
    "    # Use a temporary file path for the DDS conversion\n",
    "    with tempfile.NamedTemporaryFile(suffix='.dds', delete=False) as tmp_file:\n",
    "        tmp_dds_path = tmp_file.name\n",
    "\n",
    "    try:\n",
    "        # Create a new Wand image and explicitly import the raw pixels.\n",
    "        with WandImage(width=256, height=128) as img_wand:\n",
    "            img_wand.import_pixels(data=img_rgba_bytes, channel_map='RGBA')\n",
    "\n",
    "            # CRITICAL: Explicitly disable mipmap generation for the DDS file.\n",
    "            img_wand.options['dds:mipmaps'] = '0'\n",
    "\n",
    "            # Set the compression algorithm to DXT1 (BC1) and format to DDS\n",
    "            img_wand.compression = 'dxt1'\n",
    "            img_wand.format = 'dds'\n",
    "            img_wand.save(filename=tmp_dds_path)\n",
    "\n",
    "        # Read the temporary DDS file back into memory\n",
    "        with open(tmp_dds_path, 'rb') as f:\n",
    "            dds_data = f.read()\n",
    "\n",
    "    finally:\n",
    "        # Clean up the temporary file\n",
    "        os.remove(tmp_dds_path)\n",
    "\n",
    "    # Strip the 128-byte DDS header to get the raw DXT1 data\n",
    "    DDS_HEADER_SIZE = 128\n",
    "    dxt1_data = dds_data[DDS_HEADER_SIZE:]\n",
    "\n",
    "    # Verify the size of the compressed data\n",
    "    expected_size = 16384\n",
    "    if len(dxt1_data) != expected_size:\n",
    "        raise RuntimeError(\n",
    "            f\"DXT1 compression produced unexpected size: {len(dxt1_data)} bytes. Expected {expected_size}.\")\n",
    "\n",
    "    # Prepend the constant 16-byte ACFA header\n",
    "    return ACFA_THUMBNAIL_HEADER + dxt1_data\n",
    "\n",
    "\n",
    "def replace_thumbnail(schematic_block: bytes, new_thumbnail_bytes: bytes) -> bytes:\n",
    "    \"\"\"\n",
    "    Replaces the thumbnail data within a schematic block.\n",
    "\n",
    "    Args:\n",
    "        schematic_block: The original schematic block bytes.\n",
    "        new_thumbnail_bytes: The new thumbnail data (must be 0x4010 bytes).\n",
    "\n",
    "    Returns:\n",
    "        A new schematic block bytes object with the thumbnail replaced.\n",
    "    \"\"\"\n",
    "    if len(new_thumbnail_bytes) != 0x4010:\n",
    "        raise ValueError(\"New thumbnail data must be 0x4010 bytes long.\")\n",
    "\n",
    "    THUMBNAIL_LOCAL_OFFSET = 0x1EC4\n",
    "    THUMBNAIL_SIZE = 0x4010\n",
    "\n",
    "    # Create a mutable copy and replace the thumbnail data\n",
    "    mutable_block = bytearray(schematic_block)\n",
    "    mutable_block[THUMBNAIL_LOCAL_OFFSET:THUMBNAIL_LOCAL_OFFSET +\n",
    "                  THUMBNAIL_SIZE] = new_thumbnail_bytes\n",
    "\n",
    "    return bytes(mutable_block)\n",
    "\n",
    "\n",
    "def save_schematic_block_as_ac4a(hex_block: bytes):\n",
    "    \"\"\"\n",
    "    Saves a single schematic block to  'output/{schematic_name}_{designer_name}.ac4a' file.\n",
    "    \"\"\"\n",
    "    sch_data = display_schematic_info(hex_block)\n",
    "    schematic_name = sch_data['name']\n",
    "    designer_name = sch_data['designer']\n",
    "    output_path = f\"output/{schematic_name}_{designer_name}.ac4a\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(hex_block)\n",
    "\n",
    "\n",
    "def load_schematic_block_from_ac4a(file_path: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Loads a schematic block from a .ac4a file.\n",
    "    Returns the raw bytes representing the schematic block.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "    \n",
    "\n",
    "def insert_schematic(ac4a_path, desdoc_path):\n",
    "    BLOCK_SIZE = 24280\n",
    "    SCHEMATIC_COUNT_OFFSET = 5\n",
    "    FIRST_MARKER_OFFSET = 0x148\n",
    "\n",
    "    # Load files\n",
    "    ac4a_data = load_file(ac4a_path)\n",
    "    desdoc_data = bytearray(load_file(desdoc_path))\n",
    "\n",
    "    # Extract current schematic count\n",
    "    current_count = desdoc_data[SCHEMATIC_COUNT_OFFSET]\n",
    "    print(f\"Current active schematic count: {current_count}\")\n",
    "\n",
    "    # Calculate insertion offset\n",
    "    insertion_offset = FIRST_MARKER_OFFSET + (current_count * BLOCK_SIZE)\n",
    "\n",
    "    # Validate insertion space\n",
    "    if insertion_offset + BLOCK_SIZE > len(desdoc_data):\n",
    "        print(\"Error: Not enough space to insert schematic.\")\n",
    "        return\n",
    "\n",
    "    # Insert schematic data\n",
    "    desdoc_data[insertion_offset:insertion_offset +\n",
    "                BLOCK_SIZE] = ac4a_data[:BLOCK_SIZE]\n",
    "\n",
    "    # Update schematic count\n",
    "    desdoc_data[SCHEMATIC_COUNT_OFFSET] += 1\n",
    "    print(\n",
    "        f\"Inserted at slot {current_count + 1} (offset {hex(insertion_offset)}). New count: {desdoc_data[SCHEMATIC_COUNT_OFFSET]}\")\n",
    "\n",
    "    # Save modified DESDOC.DAT\n",
    "    save_file(desdoc_path, desdoc_data)\n",
    "\n",
    "\n",
    "def hex_dump(data: bytes, width: int = 16) -> str:\n",
    "    lines = []\n",
    "    for offset in range(0, len(data), width):\n",
    "        chunk = data[offset:offset+width]\n",
    "        hex_part = ' '.join(f'{b:02X}' for b in chunk)\n",
    "        ascii_part = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)\n",
    "        lines.append(f'{offset:08X}  {hex_part:<{width*3}}  {ascii_part}')\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949adc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_block = load_schematic_block_from_ac4a(\n",
    "    \"output/Sbeu Tarakan_Vlabus.ac4a\")\n",
    "\n",
    "# Verify loaded block content by displaying its information\n",
    "display_schematic_info(loaded_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e58952",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"sch_data/tab_sch_data/DESDOC.DAT\"\n",
    "blocks = extract_active_schematic_blocks(file_path)\n",
    "print(f\"Detected {len(blocks)} active schematic(s).\")\n",
    "\n",
    "for idx, block in enumerate(blocks, 1):\n",
    "    print(f\"Slot {idx}:\")\n",
    "    print(display_schematic_info(block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_schematic_block_as_ac4a(blocks[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6843cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_schematic(\"output/Sbeu Tarakan_Vlabus.ac4a\",\n",
    "                 \"sch_data/tab_sch_data/DESDOC.DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_part_in_ac4a_file(file_path, part_category, new_part_id):\n",
    "    \"\"\"\n",
    "    Reads an .ac4a file, swaps a part, and saves it back to the same file.\n",
    "\n",
    "    :param file_path: Path to the .ac4a schematic file.\n",
    "    :param part_category: The category of the part to swap (e.g., 'Head', 'Core').\n",
    "    :param new_part_id: The new part ID (as a string or int).\n",
    "    \"\"\"\n",
    "    \n",
    "    def _swap_part_in_block(block, part_category, new_part_id):\n",
    "        # This is a helper function nested inside for self-containment.\n",
    "        LOCAL_PARTS_OFFSET = 0xD8\n",
    "        PART_ENTRY_SIZE = 2\n",
    "        display_labels = [\n",
    "            'Head', 'Core', 'Arms', 'Legs', 'FCS', 'Generator', 'Main Booster',\n",
    "            'Back Booster', 'Side Booster', 'Overed Booster',\n",
    "            'Right Arm Unit', 'Left Arm Unit', 'Right Back Unit',\n",
    "            'Left Back Unit', 'Shoulder Unit'\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            part_index = display_labels.index(part_category)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid part category: {part_category}. Must be one of {display_labels}\")\n",
    "\n",
    "        offset = LOCAL_PARTS_OFFSET + part_index * PART_ENTRY_SIZE\n",
    "        \n",
    "        try:\n",
    "            part_id_num = int(new_part_id)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid part ID: {new_part_id}. Must be a number.\")\n",
    "\n",
    "        new_part_bytes = part_id_num.to_bytes(2, byteorder='big')\n",
    "\n",
    "        mutable_block = bytearray(block)\n",
    "        mutable_block[offset:offset + PART_ENTRY_SIZE] = new_part_bytes\n",
    "        return bytes(mutable_block)\n",
    "\n",
    "    # Main logic for the file-based swap\n",
    "    print(f\"--- Modifying {file_path} ---\")\n",
    "    \n",
    "    # 1. Load the schematic block from the file\n",
    "    try:\n",
    "        original_block = load_schematic_block_from_ac4a(file_path)\n",
    "        print(\"Original file loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Perform the swap in the loaded block\n",
    "    modified_block = _swap_part_in_block(original_block, part_category, new_part_id)\n",
    "    print(f\"Swapped '{part_category}' to part ID {new_part_id}.\")\n",
    "\n",
    "    # 3. Save the modified block back to the original file\n",
    "    save_file(file_path, modified_block)\n",
    "    print(f\"Successfully saved changes to {file_path}.\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Specify the file to modify\n",
    "ac4a_file_to_edit = \"output/AfgankaXD_RAPTOR23512.ac4a\"\n",
    "\n",
    "# Check if the file exists before trying to modify it\n",
    "if os.path.exists(ac4a_file_to_edit):\n",
    "    # 1. Show the parts list *before* the change\n",
    "    print(\"--- BEFORE ---\")\n",
    "    before_block = load_schematic_block_from_ac4a(ac4a_file_to_edit)\n",
    "    before_info = display_schematic_info(before_block)\n",
    "    # A more compact print for parts\n",
    "    for part in before_info['parts']:\n",
    "        print(f\"{part['category']}: {part['part_id']} ({part['part_name']})\")\n",
    "    print(\"\")\n",
    "\n",
    "    # 2. Call the function to swap the 'Head' to part ID '1010'\n",
    "    swap_part_in_ac4a_file(ac4a_file_to_edit, 'Right Back Unit', '2030')\n",
    "\n",
    "    # 3. Show the parts list *after* the change to verify\n",
    "    print(\"--- AFTER ---\")\n",
    "    after_block = load_schematic_block_from_ac4a(ac4a_file_to_edit)\n",
    "    after_info = display_schematic_info(after_block)\n",
    "    for part in after_info['parts']:\n",
    "        print(f\"{part['category']}: {part['part_id']} ({part['part_name']})\")\n",
    "        \n",
    "    # Example of swapping it back\n",
    "    # print(\"--- Swapping back for demonstration ---\")\n",
    "    # swap_part_in_ac4a_file(ac4a_file_to_edit, 'Head', '3010') # Assuming 3010 was the original\n",
    "\n",
    "else:\n",
    "    print(f\"Example file not found: {ac4a_file_to_edit}\")\n",
    "    print(\"Please ensure the file exists, for example by running the cell that calls 'save_schematic_block_as_ac4a'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32248d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def randomize_schematic_parts(file_path, part_mapping, new_name=None):\n",
    "    \"\"\"\n",
    "    Reads an .ac4a file, randomizes its core parts, optionally renames it, \n",
    "    and saves it back to a new file, deleting the old one.\n",
    "    Excludes debug parts (IDs starting with '9').\n",
    "\n",
    "    :param file_path: Path to the .ac4a schematic file.\n",
    "    :param part_mapping: The dictionary of all parts, loaded from the text file.\n",
    "    :param new_name: An optional new name for the schematic.\n",
    "    \"\"\"\n",
    "    # This function assumes that other necessary functions like\n",
    "    # `load_schematic_block_from_ac4a`, `save_file`, and `display_schematic_info`\n",
    "    # are already defined in the notebook.\n",
    "\n",
    "    LOCAL_PARTS_OFFSET = 0xD8\n",
    "    PART_ENTRY_SIZE = 2\n",
    "    NAME_OFFSET = 1\n",
    "    NAME_SIZE = 96  # 48 wchar_t = 96 bytes in UTF-16\n",
    "\n",
    "    lookup_keys = [\n",
    "        'Head', 'Core', 'Arms', 'Legs', 'FCS', 'Generator', 'Main Booster',\n",
    "        'Back Booster', 'Side Booster', 'Overed Booster',\n",
    "        'Arm Unit', 'Arm Unit', 'Back Unit', 'Back Unit', 'Shoulder Unit'\n",
    "    ]\n",
    "    display_labels = [\n",
    "        'Head', 'Core', 'Arms', 'Legs', 'FCS', 'Generator', 'Main Booster',\n",
    "        'Back Booster', 'Side Booster', 'Overed Booster',\n",
    "        'Right Arm Unit', 'Left Arm Unit', 'Right Back Unit',\n",
    "        'Left Back Unit', 'Shoulder Unit'\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        original_block = load_schematic_block_from_ac4a(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    mutable_block = bytearray(original_block)\n",
    "    print(f\"--- Randomizing {file_path} ---\")\n",
    "\n",
    "    # Get original designer name for the new filename\n",
    "    original_info = display_schematic_info(original_block)\n",
    "    designer_name = original_info['designer']\n",
    "\n",
    "    # Handle renaming if a new name is provided\n",
    "    if new_name:\n",
    "        if len(new_name) > (NAME_SIZE // 2) - 1:\n",
    "            new_name = new_name[:(NAME_SIZE // 2) - 1]\n",
    "            print(f\"Warning: Name truncated to '{new_name}'\")\n",
    "\n",
    "        encoded_name = new_name.encode('utf-16-le')\n",
    "        name_buffer = bytearray(NAME_SIZE)\n",
    "        name_buffer[:len(encoded_name)] = encoded_name\n",
    "        mutable_block[NAME_OFFSET:NAME_OFFSET + NAME_SIZE] = name_buffer\n",
    "        print(f\"  Renamed schematic to: {new_name}\")\n",
    "\n",
    "    for i, (lookup_key, display_label) in enumerate(zip(lookup_keys, display_labels)):\n",
    "        part_id_list = [\n",
    "            part_id for part_id in part_mapping.get(lookup_key, {}).keys()\n",
    "            if not part_id.startswith('9')\n",
    "        ]\n",
    "        if not part_id_list:\n",
    "            print(\n",
    "                f\"Warning: No valid parts found for category '{lookup_key}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        random_part_id_str = random.choice(part_id_list)\n",
    "        random_part_id_num = int(random_part_id_str)\n",
    "        offset = LOCAL_PARTS_OFFSET + i * PART_ENTRY_SIZE\n",
    "        new_part_bytes = random_part_id_num.to_bytes(2, byteorder='big')\n",
    "        mutable_block[offset:offset + PART_ENTRY_SIZE] = new_part_bytes\n",
    "        part_name = part_mapping[lookup_key][random_part_id_str]\n",
    "        print(f\"  {display_label}: {random_part_id_str} ({part_name})\")\n",
    "\n",
    "    # Determine the output path\n",
    "    if new_name:\n",
    "        output_dir = os.path.dirname(file_path)\n",
    "        new_filename = f\"{new_name}.ac4a\"\n",
    "        output_path = os.path.join(output_dir, new_filename)\n",
    "    else:\n",
    "        output_path = file_path\n",
    "\n",
    "    save_file(output_path, bytes(mutable_block))\n",
    "    print(f\"\\nSuccessfully saved randomized schematic to {output_path}.\")\n",
    "\n",
    "    # If a new name was provided, delete the old file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage for Randomizer ---\n",
    "\n",
    "# Specify the file to randomize and the new name\n",
    "ac4a_file_to_randomize = \"output/BBBB_Unknown.ac4a\"\n",
    "new_schematic_name = \"Randomized AC\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(ac4a_file_to_randomize):\n",
    "    # 1. Show the parts list *before* the change\n",
    "    print(\"--- BEFORE RANDOMIZATION ---\")\n",
    "    before_block = load_schematic_block_from_ac4a(ac4a_file_to_randomize)\n",
    "    before_info = display_schematic_info(before_block)\n",
    "    # Get designer name for verification\n",
    "    designer_name = before_info['designer']\n",
    "    print(f\"Name: {before_info['name']}\")\n",
    "    for part in before_info['parts']:\n",
    "        print(f\"  {part['category']}: {part['part_id']} ({part['part_name']})\")\n",
    "    print(\"\")\n",
    "\n",
    "    # 2. Call the randomizer function with a new name\n",
    "    randomize_schematic_parts(ac4a_file_to_randomize,\n",
    "                              part_mapping, new_name=new_schematic_name)\n",
    "    print(\"\")\n",
    "\n",
    "    # 3. Construct the new file path and verify the changes\n",
    "    new_file_path = os.path.join(\n",
    "        \"output\", f\"{new_schematic_name}.ac4a\")\n",
    "\n",
    "    print(\"--- AFTER RANDOMIZATION ---\")\n",
    "    if os.path.exists(new_file_path):\n",
    "        after_block = load_schematic_block_from_ac4a(new_file_path)\n",
    "        after_info = display_schematic_info(after_block)\n",
    "        print(f\"Name: {after_info['name']} (Saved to: {new_file_path})\")\n",
    "        for part in after_info['parts']:\n",
    "            print(\n",
    "                f\"  {part['category']}: {part['part_id']} ({part['part_name']})\")\n",
    "    else:\n",
    "        print(f\"Error: New file not found at '{new_file_path}'\")\n",
    "else:\n",
    "    print(f\"Example file not found: {ac4a_file_to_randomize}\")\n",
    "    print(\"Please ensure the file exists, for example by running a cell that calls 'save_schematic_block_as_ac4a'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_block = load_schematic_block_from_ac4a('output/Circus_Vlabus.ac4a')\n",
    "thumbnail_data = extract_thumbnail(loaded_block)\n",
    "print(f\"Extracted thumbnail data size: {len(thumbnail_data)} bytes\")\n",
    "print(hex_dump(thumbnail_data))  # Print first 64 bytes of thumbnail data\n",
    "image = bytes_to_image(thumbnail_data)\n",
    "image.show()  # Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6997a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_block = load_schematic_block_from_ac4a('output/Circus_Vlabus.ac4a')\n",
    "new_image = Image.open(\"pepe.png\")\n",
    "new_thumbnail_bytes = image_to_bytes(new_image)\n",
    "modified_block = replace_thumbnail(loaded_block, new_thumbnail_bytes)\n",
    "save_schematic_block_as_ac4a(modified_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_block = load_schematic_block_from_ac4a(\n",
    "    \"output/Circus_Vlabus.ac4a\")\n",
    "\n",
    "coloring_data, pattern_data, eye_color_data = extract_color_data(loaded_block)\n",
    "print(f\"Extracted coloring data size: {len(coloring_data)} bytes\")\n",
    "print(f\"Extracted pattern data size: {len(pattern_data)} bytes\")\n",
    "print(f\"Extracted eye color data size: {len(eye_color_data)} bytes\")\n",
    "print(\"Coloring Data:\")\n",
    "print(hex_dump(coloring_data[:64]))\n",
    "print(\"Pattern Data:\")\n",
    "print(hex_dump(pattern_data))\n",
    "print(\"Eye Color Data:\")\n",
    "print(hex_dump(eye_color_data))\n",
    "\n",
    "new_coloring_data = randomize_colors(coloring_data)\n",
    "\n",
    "print(\"New Coloring Data:\")\n",
    "print(hex_dump(new_coloring_data[:64]))\n",
    "modified_block = replace_color_data(\n",
    "    loaded_block,\n",
    "    new_colors=new_coloring_data,\n",
    ")\n",
    "save_schematic_block_as_ac4a(modified_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_block = load_schematic_block_from_ac4a(\n",
    "    \"output/Bomber_Inveigh.ac4a\")\n",
    "\n",
    "decal_data = extract_decal_data(loaded_block)\n",
    "#print(f\"Extracted decal data size: {len(decal_data)} bytes\")\n",
    "#print(\"Decal Data:\")\n",
    "#print(hex_dump(decal_data[:64]))\n",
    "\n",
    "random_decal_data = generate_full_random_decal_data()\n",
    "print(\"Random Decal Data:\")\n",
    "print(hex_dump(random_decal_data[:64]))\n",
    "modified_block = replace_decal_data(loaded_block, random_decal_data)\n",
    "save_schematic_block_as_ac4a(modified_block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_paint_data = parse_paint_dat(\"paint_data/PAINT.DAT\")\n",
    "print(f\"Extracted {len(loaded_paint_data)} emblem(s) from PAINT.DAT.\")\n",
    "print(\"Sixth Emblem Data:\")\n",
    "print(hex_dump(loaded_paint_data[5]))\n",
    "print(parse_emblem_data(loaded_paint_data[5]))\n",
    "\n",
    "for i in range(16):\n",
    "    random_emblem = generate_random_emblem(num_layers=i+1)\n",
    "    append_emblem_to_paint_dat(\"paint_data/PAINT.DAT\", random_emblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc7f7af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted coloring data size: 816 bytes\n",
      "Extracted pattern data size: 36 bytes\n",
      "Extracted eye color data size: 4 bytes\n",
      "Coloring Data:\n",
      "00000000  C6 BF 51 FF 26 9C 87 FF E3 D9 CE FF 23 F7 13 FF   ..Q.&.......#...\n",
      "00000010  C4 2C E7 FF 9B 94 D3 FF DE 91 95 FF DA FC 3B FF   .,............;.\n",
      "00000020  7A B3 A7 FF 5A A7 A8 FF 0C 3D 92 FF 4C 0D 71 FF   z...Z....=..L.q.\n",
      "00000030  8B 3F A7 FF 87 66 6A FF E4 0F A9 FF 66 43 1F FF   .?...fj.....fC..\n",
      "Pattern Data:\n",
      "00000000  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00   ................\n",
      "00000010  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00   ................\n",
      "00000020  00 00 00 00                                       ....\n",
      "Eye Color Data:\n",
      "00000000  FF 9C 00 FF                                       ....\n",
      "New Coloring Data:\n",
      "00000000  DE B4 F1 FF 64 A2 80 FF E7 9A DB FF 29 0A F0 FF   ....d.......)...\n",
      "00000010  BF 32 D2 FF 9C B0 13 FF 09 79 BB FF 56 7A AC FF   .2.......y..Vz..\n",
      "00000020  3F 9A 29 FF 85 63 E9 FF 54 03 BD FF F6 0C 65 FF   ?.)..c..T.....e.\n",
      "00000030  F8 DE D5 FF E8 C0 91 FF 77 5D 8C FF EC 26 35 FF   ........w]...&5.\n",
      "Generating layer 1/8 for part 'head'\n",
      "rand_rot_float axis 0: 1.916384161856529\n",
      "rand_rot_float axis 1: -0.02699495900541793\n",
      "rand_rot_float axis 2: 2.8454005169027567\n",
      "Generating layer 2/8 for part 'head'\n",
      "rand_rot_float axis 0: -1.1585655669319785\n",
      "rand_rot_float axis 1: -2.577963795825701\n",
      "rand_rot_float axis 2: -0.05305636944642389\n",
      "Generating layer 3/8 for part 'head'\n",
      "rand_rot_float axis 0: 1.854567799051111\n",
      "rand_rot_float axis 1: -2.3496953759616668\n",
      "rand_rot_float axis 2: -0.9249146556013317\n",
      "Generating layer 4/8 for part 'head'\n",
      "rand_rot_float axis 0: -0.8737441865830538\n",
      "rand_rot_float axis 1: -0.2894887160705699\n",
      "rand_rot_float axis 2: -2.395097817653923\n",
      "Generating layer 5/8 for part 'head'\n",
      "rand_rot_float axis 0: 2.5534565220870933\n",
      "rand_rot_float axis 1: -2.564163719537811\n",
      "rand_rot_float axis 2: 1.1734567822803044\n",
      "Generating layer 6/8 for part 'head'\n",
      "rand_rot_float axis 0: 1.4912163522430664\n",
      "rand_rot_float axis 1: 1.0960730577535491\n",
      "rand_rot_float axis 2: -0.06907925703039641\n",
      "Generating layer 7/8 for part 'head'\n",
      "rand_rot_float axis 0: -2.733949107139324\n",
      "rand_rot_float axis 1: 2.5562869102826875\n",
      "rand_rot_float axis 2: 0.3333525245499831\n",
      "Generating layer 8/8 for part 'head'\n",
      "rand_rot_float axis 0: -2.3048726541247495\n",
      "rand_rot_float axis 1: 2.4403958822151894\n",
      "rand_rot_float axis 2: 2.2105789223650474\n",
      "Generating layer 1/8 for part 'core'\n",
      "rand_rot_float axis 0: 2.381627155472268\n",
      "rand_rot_float axis 1: -1.118032766827365\n",
      "rand_rot_float axis 2: 2.0300966246013337\n",
      "Generating layer 2/8 for part 'core'\n",
      "rand_rot_float axis 0: -2.7626979081536547\n",
      "rand_rot_float axis 1: -1.4014845452569251\n",
      "rand_rot_float axis 2: 2.7373268917114366\n",
      "Generating layer 3/8 for part 'core'\n",
      "rand_rot_float axis 0: -1.3339326319947438\n",
      "rand_rot_float axis 1: 2.5488117098675804\n",
      "rand_rot_float axis 2: -2.857622360244088\n",
      "Generating layer 4/8 for part 'core'\n",
      "rand_rot_float axis 0: 1.015450616236893\n",
      "rand_rot_float axis 1: 1.0615420550485828\n",
      "rand_rot_float axis 2: 0.7873179847866107\n",
      "Generating layer 5/8 for part 'core'\n",
      "rand_rot_float axis 0: 2.25691295191762\n",
      "rand_rot_float axis 1: -2.794332092371389\n",
      "rand_rot_float axis 2: 1.8331511049471976\n",
      "Generating layer 6/8 for part 'core'\n",
      "rand_rot_float axis 0: -0.852439260091836\n",
      "rand_rot_float axis 1: 0.8657018852030465\n",
      "rand_rot_float axis 2: 2.0068776189445137\n",
      "Generating layer 7/8 for part 'core'\n",
      "rand_rot_float axis 0: 3.0928476585559883\n",
      "rand_rot_float axis 1: 0.07436279589198369\n",
      "rand_rot_float axis 2: 1.829249700158198\n",
      "Generating layer 8/8 for part 'core'\n",
      "rand_rot_float axis 0: -1.221034468172009\n",
      "rand_rot_float axis 1: -1.0336277024120109\n",
      "rand_rot_float axis 2: 2.7086887223968814\n",
      "Generating layer 1/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: 2.0098885992927515\n",
      "rand_rot_float axis 1: -0.131459451030838\n",
      "rand_rot_float axis 2: 1.0978692576111255\n",
      "Generating layer 2/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: 2.176645487649517\n",
      "rand_rot_float axis 1: -0.30308012538410045\n",
      "rand_rot_float axis 2: -0.7586787629956357\n",
      "Generating layer 3/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: -0.9447539219617327\n",
      "rand_rot_float axis 1: 2.075932990333313\n",
      "rand_rot_float axis 2: 2.2998371716072725\n",
      "Generating layer 4/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: -2.116592880846558\n",
      "rand_rot_float axis 1: 2.50025606426518\n",
      "rand_rot_float axis 2: -3.1187474694095685\n",
      "Generating layer 5/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: -2.631195216788181\n",
      "rand_rot_float axis 1: -1.6040107022974612\n",
      "rand_rot_float axis 2: 1.813643252986406\n",
      "Generating layer 6/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: -0.6745424066523045\n",
      "rand_rot_float axis 1: 1.9393124410891378\n",
      "rand_rot_float axis 2: 0.8815602064468999\n",
      "Generating layer 7/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: -0.47430204775250306\n",
      "rand_rot_float axis 1: -1.44855857791226\n",
      "rand_rot_float axis 2: 0.1844160851760699\n",
      "Generating layer 8/8 for part 'arm_right'\n",
      "rand_rot_float axis 0: -1.16810475343185\n",
      "rand_rot_float axis 1: -0.22484733317432548\n",
      "rand_rot_float axis 2: -0.2670469643237361\n",
      "Generating layer 1/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: -1.469692746847519\n",
      "rand_rot_float axis 1: 0.4395833720750022\n",
      "rand_rot_float axis 2: 1.46879563621125\n",
      "Generating layer 2/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: 2.139036245538281\n",
      "rand_rot_float axis 1: 1.421453710546687\n",
      "rand_rot_float axis 2: 1.5099100300343347\n",
      "Generating layer 3/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: 1.7525228816223661\n",
      "rand_rot_float axis 1: 1.6356569224050856\n",
      "rand_rot_float axis 2: -1.233987637958679\n",
      "Generating layer 4/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: -1.5022737843059826\n",
      "rand_rot_float axis 1: 2.176436899267883\n",
      "rand_rot_float axis 2: 2.37899172298407\n",
      "Generating layer 5/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: -2.721251919382648\n",
      "rand_rot_float axis 1: 2.3888508063493568\n",
      "rand_rot_float axis 2: 2.5590321092701442\n",
      "Generating layer 6/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: 2.5584198796301125\n",
      "rand_rot_float axis 1: -0.38207589012135346\n",
      "rand_rot_float axis 2: -1.0574483491366884\n",
      "Generating layer 7/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: -2.5558970129768936\n",
      "rand_rot_float axis 1: 1.381147015166591\n",
      "rand_rot_float axis 2: 2.376583705950634\n",
      "Generating layer 8/8 for part 'arm_left'\n",
      "rand_rot_float axis 0: 2.676098982848556\n",
      "rand_rot_float axis 1: -1.6609591861223585\n",
      "rand_rot_float axis 2: 1.4197864254634576\n",
      "Generating layer 1/8 for part 'legs'\n",
      "rand_rot_float axis 0: 1.2346343026647304\n",
      "rand_rot_float axis 1: -2.558301983107079\n",
      "rand_rot_float axis 2: 2.7816984957700175\n",
      "Generating layer 2/8 for part 'legs'\n",
      "rand_rot_float axis 0: 1.4155100852273996\n",
      "rand_rot_float axis 1: -0.6721043589981344\n",
      "rand_rot_float axis 2: 2.9636779450961637\n",
      "Generating layer 3/8 for part 'legs'\n",
      "rand_rot_float axis 0: -0.18586194471669737\n",
      "rand_rot_float axis 1: -2.6906766900545085\n",
      "rand_rot_float axis 2: 0.8530227495501075\n",
      "Generating layer 4/8 for part 'legs'\n",
      "rand_rot_float axis 0: 0.9629695477473605\n",
      "rand_rot_float axis 1: -0.5727978581402975\n",
      "rand_rot_float axis 2: 0.3690266845571193\n",
      "Generating layer 5/8 for part 'legs'\n",
      "rand_rot_float axis 0: 1.9746279011057384\n",
      "rand_rot_float axis 1: -0.12070114571248913\n",
      "rand_rot_float axis 2: -2.9343155308578956\n",
      "Generating layer 6/8 for part 'legs'\n",
      "rand_rot_float axis 0: -1.3303769413529543\n",
      "rand_rot_float axis 1: -1.4552674083480373\n",
      "rand_rot_float axis 2: -3.014222712215385\n",
      "Generating layer 7/8 for part 'legs'\n",
      "rand_rot_float axis 0: -2.980665559660596\n",
      "rand_rot_float axis 1: 1.165086303459323\n",
      "rand_rot_float axis 2: 1.9873551218492684\n",
      "Generating layer 8/8 for part 'legs'\n",
      "rand_rot_float axis 0: 2.263517990358263\n",
      "rand_rot_float axis 1: 2.9589502247986417\n",
      "rand_rot_float axis 2: -1.9498058136019498\n",
      "Random Decal Data:\n",
      "00000000  02 00 00 00 96 24 03 26 21 43 4D 00 00 00 00 00   .....$.&!CM.....\n",
      "00000010  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00   ................\n",
      "00000020  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00   ................\n",
      "00000030  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00   ................\n"
     ]
    }
   ],
   "source": [
    "loaded_block = load_schematic_block_from_ac4a(\n",
    "    \"output/Bomber_Inveigh.ac4a\")\n",
    "\n",
    "coloring_data, pattern_data, eye_color_data = extract_color_data(loaded_block)\n",
    "print(f\"Extracted coloring data size: {len(coloring_data)} bytes\")\n",
    "print(f\"Extracted pattern data size: {len(pattern_data)} bytes\")\n",
    "print(f\"Extracted eye color data size: {len(eye_color_data)} bytes\")\n",
    "print(\"Coloring Data:\")\n",
    "print(hex_dump(coloring_data[:64]))\n",
    "print(\"Pattern Data:\")\n",
    "print(hex_dump(pattern_data))\n",
    "print(\"Eye Color Data:\")\n",
    "print(hex_dump(eye_color_data))\n",
    "\n",
    "new_coloring_data = randomize_colors(coloring_data)\n",
    "\n",
    "print(\"New Coloring Data:\")\n",
    "print(hex_dump(new_coloring_data[:64]))\n",
    "modified_block = replace_color_data(\n",
    "    loaded_block,\n",
    "    new_colors=new_coloring_data,\n",
    ")\n",
    "\n",
    "decal_data = extract_decal_data(modified_block)\n",
    "# print(f\"Extracted decal data size: {len(decal_data)} bytes\")\n",
    "# print(\"Decal Data:\")\n",
    "# print(hex_dump(decal_data[:64]))\n",
    "\n",
    "random_decal_data = generate_full_random_decal_data()\n",
    "print(\"Random Decal Data:\")\n",
    "print(hex_dump(random_decal_data[:64]))\n",
    "modified_block = replace_decal_data(modified_block, random_decal_data)\n",
    "save_schematic_block_as_ac4a(modified_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b2a7d5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BEFORE RANDOMIZATION ---\n",
      "Name: Bomber\n",
      "  Head: 1020 (HD-JUDITH)\n",
      "  Core: 1031 (CR-LAHIRE)\n",
      "  Arms: 1041 (AM-LAHIRE)\n",
      "  Legs: 1041 (LG-LAHIRE)\n",
      "  FCS: 2010 (INBLUE)\n",
      "  Generator: 1051 (GN-SOBRERO)\n",
      "  Main Booster: 2010 (S04-VIRTUE)\n",
      "  Back Booster: 4021 (BB11-LATONA)\n",
      "  Side Booster: 4010 (SB128-SCHEDAR)\n",
      "  Overed Booster: 1010 (KB-JUDITH)\n",
      "  Right Arm Unit: 1030 (MR-R102)\n",
      "  Left Arm Unit: 2030 (03-MOTORCOBRA)\n",
      "  Right Back Unit: 5061 (SAPLA)\n",
      "  Left Back Unit: 5061 (SAPLA)\n",
      "  Shoulder Unit: 0071 (GUYANDOTTE04)\n",
      "\n",
      "--- Randomizing output/Bomber_Inveigh.ac4a ---\n",
      "  Renamed schematic to: Randomized AC5\n",
      "  Head: 0010 (GAN01-SS-H)\n",
      "  Core: 4010 (C01-TELLUS)\n",
      "  Arms: 2010 (03-AALIYAH/A)\n",
      "  Legs: 2120 (04-ALICIA/L)\n",
      "  FCS: 2030 (BLUEXS)\n",
      "  Generator: 1030 (GN-JUDITH)\n",
      "  Main Booster: 4010 (MB107-POLARIS)\n",
      "  Back Booster: 2010 (03-AALIYAH/B)\n",
      "  Side Booster: 4010 (SB128-SCHEDAR)\n",
      "  Overed Booster: 1031 (KRB-PALLAS)\n",
      "  Right Arm Unit: 2040 (02-DRAGONSLAYER)\n",
      "  Left Arm Unit: 1091 (AR-O700)\n",
      "  Right Back Unit: 0090 (OSAGE03)\n",
      "  Left Back Unit: 0151 (GAN01-SS-GC)\n",
      "  Shoulder Unit: 2020 (09-FLICKER)\n",
      "\n",
      "Successfully saved randomized schematic to output\\Randomized AC5.ac4a.\n",
      "\n",
      "--- AFTER RANDOMIZATION ---\n",
      "Name: Randomized AC5 (Saved to: output\\Randomized AC5.ac4a)\n",
      "  Head: 0010 (GAN01-SS-H)\n",
      "  Core: 4010 (C01-TELLUS)\n",
      "  Arms: 2010 (03-AALIYAH/A)\n",
      "  Legs: 2120 (04-ALICIA/L)\n",
      "  FCS: 2030 (BLUEXS)\n",
      "  Generator: 1030 (GN-JUDITH)\n",
      "  Main Booster: 4010 (MB107-POLARIS)\n",
      "  Back Booster: 2010 (03-AALIYAH/B)\n",
      "  Side Booster: 4010 (SB128-SCHEDAR)\n",
      "  Overed Booster: 1031 (KRB-PALLAS)\n",
      "  Right Arm Unit: 2040 (02-DRAGONSLAYER)\n",
      "  Left Arm Unit: 1091 (AR-O700)\n",
      "  Right Back Unit: 0090 (OSAGE03)\n",
      "  Left Back Unit: 0151 (GAN01-SS-GC)\n",
      "  Shoulder Unit: 2020 (09-FLICKER)\n"
     ]
    }
   ],
   "source": [
    "ac4a_file_to_randomize = \"output/Bomber_Inveigh.ac4a\"\n",
    "new_schematic_name = \"Randomized AC5\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(ac4a_file_to_randomize):\n",
    "    # 1. Show the parts list *before* the change\n",
    "    print(\"--- BEFORE RANDOMIZATION ---\")\n",
    "    before_block = load_schematic_block_from_ac4a(ac4a_file_to_randomize)\n",
    "    before_info = display_schematic_info(before_block)\n",
    "    # Get designer name for verification\n",
    "    designer_name = before_info['designer']\n",
    "    print(f\"Name: {before_info['name']}\")\n",
    "    for part in before_info['parts']:\n",
    "        print(f\"  {part['category']}: {part['part_id']} ({part['part_name']})\")\n",
    "    print(\"\")\n",
    "\n",
    "    # 2. Call the randomizer function with a new name\n",
    "    randomize_schematic_parts(ac4a_file_to_randomize,\n",
    "                              part_mapping, new_name=new_schematic_name)\n",
    "    print(\"\")\n",
    "\n",
    "    # 3. Construct the new file path and verify the changes\n",
    "    new_file_path = os.path.join(\n",
    "        \"output\", f\"{new_schematic_name}.ac4a\")\n",
    "\n",
    "    print(\"--- AFTER RANDOMIZATION ---\")\n",
    "    if os.path.exists(new_file_path):\n",
    "        after_block = load_schematic_block_from_ac4a(new_file_path)\n",
    "        after_info = display_schematic_info(after_block)\n",
    "        print(f\"Name: {after_info['name']} (Saved to: {new_file_path})\")\n",
    "        for part in after_info['parts']:\n",
    "            print(\n",
    "                f\"  {part['category']}: {part['part_id']} ({part['part_name']})\")\n",
    "    else:\n",
    "        print(f\"Error: New file not found at '{new_file_path}'\")\n",
    "else:\n",
    "    print(f\"Example file not found: {ac4a_file_to_randomize}\")\n",
    "    print(\"Please ensure the file exists, for example by running a cell that calls 'save_schematic_block_as_ac4a'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
